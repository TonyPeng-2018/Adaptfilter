{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weight in pretrained mobilnetv2\n",
    "import torch\n",
    "weight = torch.load('./Weights/imagenet/pretrained/pretrained_mobilenetv2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonypeng/anaconda3/envs/iot/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tonypeng/anaconda3/envs/iot/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/tonypeng/anaconda3/envs/iot/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/tonypeng/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:03<00:00, 34.1MB/s]\n",
      "/home/tonypeng/anaconda3/envs/iot/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /home/tonypeng/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n",
      "100%|██████████| 230M/230M [00:07<00:00, 34.5MB/s] \n",
      "/home/tonypeng/anaconda3/envs/iot/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/tonypeng/anaconda3/envs/iot/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to /home/tonypeng/.cache/torch/hub/checkpoints/mobilenet_v3_large-8738ca79.pth\n",
      "100%|██████████| 21.1M/21.1M [00:00<00:00, 31.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "# get the resnet 18 and resnet 50, 152\n",
    "from torchvision import models\n",
    "resnet18 = models.resnet18(pretrained=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "resnet50 = models.resnet50(pretrained=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "resnet152 = models.resnet152(pretrained=models.ResNet152_Weights.IMAGENET1K_V2)\n",
    "mobilenetv2 = models.mobilenet_v2(pretrained=models.MobileNet_V2_Weights.IMAGENET1K_V2)\n",
    "mobilenetv3 = models.mobilenet_v3_large(pretrained=models.MobileNet_V3_Large_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# store these weights\n",
    "torch.save(resnet18.state_dict(), './Weights/imagenet/pretrained/resnet18.pth')\n",
    "torch.save(resnet50.state_dict(), './Weights/imagenet/pretrained/resnet50.pth')\n",
    "torch.save(resnet152.state_dict(), './Weights/imagenet/pretrained/resnet152.pth')\n",
    "torch.save(mobilenetv2.state_dict(), './Weights/imagenet/pretrained/mobilenetv2.pth')\n",
    "torch.save(mobilenetv3.state_dict(), './Weights/imagenet/pretrained/mobilenetv3.pth')\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.mobilenetv2_original import MobileNetV2_client, MobileNetV2_server\n",
    "import os \n",
    "\n",
    "def stupid_model_splitter(num_classes = 1000, weight_root = '', device = 'cuda:0', partition = -1):\n",
    "    # here are have a very stupid splitter for \n",
    "    # the restnet101 mode\n",
    "    # assert that they have at least the same length of models\n",
    "\n",
    "    c_model = MobileNetV2_client()\n",
    "    s_model = MobileNetV2_server(num_classes = num_classes)\n",
    "\n",
    "    c_weight = c_model.state_dict()\n",
    "    s_weight = s_model.state_dict()\n",
    "    c_weight_key = list(c_weight.keys())\n",
    "    s_weight_key = list(s_weight.keys())\n",
    "\n",
    "    if partition == -1:\n",
    "        partition = len(c_weight_key)\n",
    "\n",
    "    cw_path = weight_root + '/client/mobilenetv2.pth'\n",
    "    sw_path = weight_root + '/server/mobilenetv2.pth'\n",
    "    if not os.path.exists(cw_path):\n",
    "        pw_path = weight_root + '/pretrained/mobilenetv2.pth'\n",
    "        in_weight = torch.load(pw_path, map_location=device)\n",
    "        assert (len(c_weight_key) + len(s_weight_key) == len(in_weight))\n",
    "\n",
    "        # reivese the key of weights\n",
    "        in_weight_keys = list(in_weight.keys())\n",
    "        for i in range(len(in_weight_keys)):\n",
    "            if i < partition:\n",
    "                c_weight[c_weight_key[i]] = in_weight[in_weight_keys[i]]\n",
    "            else:\n",
    "                s_weight[s_weight_key[i-partition]] = in_weight[in_weight_keys[i]]\n",
    "        # store the weights\n",
    "        if not os.path.exists(weight_root + '/client'):\n",
    "            os.makedirs(weight_root + '/client')\n",
    "        if not os.path.exists(weight_root + '/server'):\n",
    "            os.makedirs(weight_root + '/server')\n",
    "\n",
    "        torch.save(c_weight, './Weights/imagenet/client/mobilenetv2.pth')\n",
    "        torch.save(s_weight, './Weights/imagenet/server/mobilenetv2.pth')\n",
    "    \n",
    "    c_model.load_state_dict(torch.load(cw_path, map_location=device))\n",
    "    s_model.load_state_dict(torch.load(sw_path, map_location=device))\n",
    "    return c_model, s_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['features.0.0.weight', 'features.0.1.weight', 'features.0.1.bias', 'features.0.1.running_mean', 'features.0.1.running_var', 'features.0.1.num_batches_tracked', 'features.1.conv.0.0.weight', 'features.1.conv.0.1.weight', 'features.1.conv.0.1.bias', 'features.1.conv.0.1.running_mean', 'features.1.conv.0.1.running_var', 'features.1.conv.0.1.num_batches_tracked', 'features.1.conv.1.weight', 'features.1.conv.2.weight', 'features.1.conv.2.bias', 'features.1.conv.2.running_mean', 'features.1.conv.2.running_var', 'features.1.conv.2.num_batches_tracked', 'features.2.conv.0.0.weight', 'features.2.conv.0.1.weight', 'features.2.conv.0.1.bias', 'features.2.conv.0.1.running_mean', 'features.2.conv.0.1.running_var', 'features.2.conv.0.1.num_batches_tracked', 'features.2.conv.1.0.weight', 'features.2.conv.1.1.weight', 'features.2.conv.1.1.bias', 'features.2.conv.1.1.running_mean', 'features.2.conv.1.1.running_var', 'features.2.conv.1.1.num_batches_tracked', 'features.2.conv.2.weight', 'features.2.conv.3.weight', 'features.2.conv.3.bias', 'features.2.conv.3.running_mean', 'features.2.conv.3.running_var', 'features.2.conv.3.num_batches_tracked', 'features.3.conv.0.0.weight', 'features.3.conv.0.1.weight', 'features.3.conv.0.1.bias', 'features.3.conv.0.1.running_mean', 'features.3.conv.0.1.running_var', 'features.3.conv.0.1.num_batches_tracked', 'features.3.conv.1.0.weight', 'features.3.conv.1.1.weight', 'features.3.conv.1.1.bias', 'features.3.conv.1.1.running_mean', 'features.3.conv.1.1.running_var', 'features.3.conv.1.1.num_batches_tracked', 'features.3.conv.2.weight', 'features.3.conv.3.weight', 'features.3.conv.3.bias', 'features.3.conv.3.running_mean', 'features.3.conv.3.running_var', 'features.3.conv.3.num_batches_tracked', 'features.4.conv.0.0.weight', 'features.4.conv.0.1.weight', 'features.4.conv.0.1.bias', 'features.4.conv.0.1.running_mean', 'features.4.conv.0.1.running_var', 'features.4.conv.0.1.num_batches_tracked', 'features.4.conv.1.0.weight', 'features.4.conv.1.1.weight', 'features.4.conv.1.1.bias', 'features.4.conv.1.1.running_mean', 'features.4.conv.1.1.running_var', 'features.4.conv.1.1.num_batches_tracked', 'features.4.conv.2.weight', 'features.4.conv.3.weight', 'features.4.conv.3.bias', 'features.4.conv.3.running_mean', 'features.4.conv.3.running_var', 'features.4.conv.3.num_batches_tracked', 'features.5.conv.0.0.weight', 'features.5.conv.0.1.weight', 'features.5.conv.0.1.bias', 'features.5.conv.0.1.running_mean', 'features.5.conv.0.1.running_var', 'features.5.conv.0.1.num_batches_tracked', 'features.5.conv.1.0.weight', 'features.5.conv.1.1.weight', 'features.5.conv.1.1.bias', 'features.5.conv.1.1.running_mean', 'features.5.conv.1.1.running_var', 'features.5.conv.1.1.num_batches_tracked', 'features.5.conv.2.weight', 'features.5.conv.3.weight', 'features.5.conv.3.bias', 'features.5.conv.3.running_mean', 'features.5.conv.3.running_var', 'features.5.conv.3.num_batches_tracked', 'features.6.conv.0.0.weight', 'features.6.conv.0.1.weight', 'features.6.conv.0.1.bias', 'features.6.conv.0.1.running_mean', 'features.6.conv.0.1.running_var', 'features.6.conv.0.1.num_batches_tracked', 'features.6.conv.1.0.weight', 'features.6.conv.1.1.weight', 'features.6.conv.1.1.bias', 'features.6.conv.1.1.running_mean', 'features.6.conv.1.1.running_var', 'features.6.conv.1.1.num_batches_tracked', 'features.6.conv.2.weight', 'features.6.conv.3.weight', 'features.6.conv.3.bias', 'features.6.conv.3.running_mean', 'features.6.conv.3.running_var', 'features.6.conv.3.num_batches_tracked', 'features.7.conv.0.0.weight', 'features.7.conv.0.1.weight', 'features.7.conv.0.1.bias', 'features.7.conv.0.1.running_mean', 'features.7.conv.0.1.running_var', 'features.7.conv.0.1.num_batches_tracked', 'features.7.conv.1.0.weight', 'features.7.conv.1.1.weight', 'features.7.conv.1.1.bias', 'features.7.conv.1.1.running_mean', 'features.7.conv.1.1.running_var', 'features.7.conv.1.1.num_batches_tracked', 'features.7.conv.2.weight', 'features.7.conv.3.weight', 'features.7.conv.3.bias', 'features.7.conv.3.running_mean', 'features.7.conv.3.running_var', 'features.7.conv.3.num_batches_tracked', 'features.8.conv.0.0.weight', 'features.8.conv.0.1.weight', 'features.8.conv.0.1.bias', 'features.8.conv.0.1.running_mean', 'features.8.conv.0.1.running_var', 'features.8.conv.0.1.num_batches_tracked', 'features.8.conv.1.0.weight', 'features.8.conv.1.1.weight', 'features.8.conv.1.1.bias', 'features.8.conv.1.1.running_mean', 'features.8.conv.1.1.running_var', 'features.8.conv.1.1.num_batches_tracked', 'features.8.conv.2.weight', 'features.8.conv.3.weight', 'features.8.conv.3.bias', 'features.8.conv.3.running_mean', 'features.8.conv.3.running_var', 'features.8.conv.3.num_batches_tracked', 'features.9.conv.0.0.weight', 'features.9.conv.0.1.weight', 'features.9.conv.0.1.bias', 'features.9.conv.0.1.running_mean', 'features.9.conv.0.1.running_var', 'features.9.conv.0.1.num_batches_tracked', 'features.9.conv.1.0.weight', 'features.9.conv.1.1.weight', 'features.9.conv.1.1.bias', 'features.9.conv.1.1.running_mean', 'features.9.conv.1.1.running_var', 'features.9.conv.1.1.num_batches_tracked', 'features.9.conv.2.weight', 'features.9.conv.3.weight', 'features.9.conv.3.bias', 'features.9.conv.3.running_mean', 'features.9.conv.3.running_var', 'features.9.conv.3.num_batches_tracked', 'features.10.conv.0.0.weight', 'features.10.conv.0.1.weight', 'features.10.conv.0.1.bias', 'features.10.conv.0.1.running_mean', 'features.10.conv.0.1.running_var', 'features.10.conv.0.1.num_batches_tracked', 'features.10.conv.1.0.weight', 'features.10.conv.1.1.weight', 'features.10.conv.1.1.bias', 'features.10.conv.1.1.running_mean', 'features.10.conv.1.1.running_var', 'features.10.conv.1.1.num_batches_tracked', 'features.10.conv.2.weight', 'features.10.conv.3.weight', 'features.10.conv.3.bias', 'features.10.conv.3.running_mean', 'features.10.conv.3.running_var', 'features.10.conv.3.num_batches_tracked', 'features.11.conv.0.0.weight', 'features.11.conv.0.1.weight', 'features.11.conv.0.1.bias', 'features.11.conv.0.1.running_mean', 'features.11.conv.0.1.running_var', 'features.11.conv.0.1.num_batches_tracked', 'features.11.conv.1.0.weight', 'features.11.conv.1.1.weight', 'features.11.conv.1.1.bias', 'features.11.conv.1.1.running_mean', 'features.11.conv.1.1.running_var', 'features.11.conv.1.1.num_batches_tracked', 'features.11.conv.2.weight', 'features.11.conv.3.weight', 'features.11.conv.3.bias', 'features.11.conv.3.running_mean', 'features.11.conv.3.running_var', 'features.11.conv.3.num_batches_tracked', 'features.12.conv.0.0.weight', 'features.12.conv.0.1.weight', 'features.12.conv.0.1.bias', 'features.12.conv.0.1.running_mean', 'features.12.conv.0.1.running_var', 'features.12.conv.0.1.num_batches_tracked', 'features.12.conv.1.0.weight', 'features.12.conv.1.1.weight', 'features.12.conv.1.1.bias', 'features.12.conv.1.1.running_mean', 'features.12.conv.1.1.running_var', 'features.12.conv.1.1.num_batches_tracked', 'features.12.conv.2.weight', 'features.12.conv.3.weight', 'features.12.conv.3.bias', 'features.12.conv.3.running_mean', 'features.12.conv.3.running_var', 'features.12.conv.3.num_batches_tracked', 'features.13.conv.0.0.weight', 'features.13.conv.0.1.weight', 'features.13.conv.0.1.bias', 'features.13.conv.0.1.running_mean', 'features.13.conv.0.1.running_var', 'features.13.conv.0.1.num_batches_tracked', 'features.13.conv.1.0.weight', 'features.13.conv.1.1.weight', 'features.13.conv.1.1.bias', 'features.13.conv.1.1.running_mean', 'features.13.conv.1.1.running_var', 'features.13.conv.1.1.num_batches_tracked', 'features.13.conv.2.weight', 'features.13.conv.3.weight', 'features.13.conv.3.bias', 'features.13.conv.3.running_mean', 'features.13.conv.3.running_var', 'features.13.conv.3.num_batches_tracked', 'features.14.conv.0.0.weight', 'features.14.conv.0.1.weight', 'features.14.conv.0.1.bias', 'features.14.conv.0.1.running_mean', 'features.14.conv.0.1.running_var', 'features.14.conv.0.1.num_batches_tracked', 'features.14.conv.1.0.weight', 'features.14.conv.1.1.weight', 'features.14.conv.1.1.bias', 'features.14.conv.1.1.running_mean', 'features.14.conv.1.1.running_var', 'features.14.conv.1.1.num_batches_tracked', 'features.14.conv.2.weight', 'features.14.conv.3.weight', 'features.14.conv.3.bias', 'features.14.conv.3.running_mean', 'features.14.conv.3.running_var', 'features.14.conv.3.num_batches_tracked', 'features.15.conv.0.0.weight', 'features.15.conv.0.1.weight', 'features.15.conv.0.1.bias', 'features.15.conv.0.1.running_mean', 'features.15.conv.0.1.running_var', 'features.15.conv.0.1.num_batches_tracked', 'features.15.conv.1.0.weight', 'features.15.conv.1.1.weight', 'features.15.conv.1.1.bias', 'features.15.conv.1.1.running_mean', 'features.15.conv.1.1.running_var', 'features.15.conv.1.1.num_batches_tracked', 'features.15.conv.2.weight', 'features.15.conv.3.weight', 'features.15.conv.3.bias', 'features.15.conv.3.running_mean', 'features.15.conv.3.running_var', 'features.15.conv.3.num_batches_tracked', 'features.16.conv.0.0.weight', 'features.16.conv.0.1.weight', 'features.16.conv.0.1.bias', 'features.16.conv.0.1.running_mean', 'features.16.conv.0.1.running_var', 'features.16.conv.0.1.num_batches_tracked', 'features.16.conv.1.0.weight', 'features.16.conv.1.1.weight', 'features.16.conv.1.1.bias', 'features.16.conv.1.1.running_mean', 'features.16.conv.1.1.running_var', 'features.16.conv.1.1.num_batches_tracked', 'features.16.conv.2.weight', 'features.16.conv.3.weight', 'features.16.conv.3.bias', 'features.16.conv.3.running_mean', 'features.16.conv.3.running_var', 'features.16.conv.3.num_batches_tracked', 'features.17.conv.0.0.weight', 'features.17.conv.0.1.weight', 'features.17.conv.0.1.bias', 'features.17.conv.0.1.running_mean', 'features.17.conv.0.1.running_var', 'features.17.conv.0.1.num_batches_tracked', 'features.17.conv.1.0.weight', 'features.17.conv.1.1.weight', 'features.17.conv.1.1.bias', 'features.17.conv.1.1.running_mean', 'features.17.conv.1.1.running_var', 'features.17.conv.1.1.num_batches_tracked', 'features.17.conv.2.weight', 'features.17.conv.3.weight', 'features.17.conv.3.bias', 'features.17.conv.3.running_mean', 'features.17.conv.3.running_var', 'features.17.conv.3.num_batches_tracked', 'features.18.0.weight', 'features.18.1.weight', 'features.18.1.bias', 'features.18.1.running_mean', 'features.18.1.running_var', 'features.18.1.num_batches_tracked', 'classifier.1.weight', 'classifier.1.bias'])\n",
      "MobileNetV2_client(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "MobileNetV2_server(\n",
      "  (features): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): Conv2dNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load the weight in pretrained imagenet\n",
    "import torch\n",
    "mobilenetv2 = torch.load('./Weights/imagenet/pretrained/mobilenetv2.pth')\n",
    "print(mobilenetv2.keys())\n",
    "\n",
    "# get the mobilenetv2 client and server\n",
    "client, server = stupid_model_splitter(weight_root = './Weights/imagenet', partition = 3)\n",
    "print(client)\n",
    "print(server)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "926\n",
      "932\n"
     ]
    }
   ],
   "source": [
    "from Models import mobilenetv2, mobilenetv3, resnet\n",
    "mv2 = mobilenetv2.mobilenetv2_splitter()\n",
    "mv3 = mobilenetv3.mobilenetv3_splitter()\n",
    "rn = resnet.resnet_splitter(layers=152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=40, bias=True)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Linear(in_features=40, out_features=50, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "total_model = torchvision.models.mobilenet_v2()\n",
    "class t_model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.part1 = torch.nn.Sequential(nn.Linear(10,20))\n",
    "        self.part2 = torch.nn.Sequential(nn.Linear(20,40))\n",
    "        self.part3 = torch.nn.Sequential(nn.Linear(40,50))\n",
    "    def forward(self, x):\n",
    "        out = self.part1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.part2(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = self.part3(out)\n",
    "        return out\n",
    "client = t_model()\n",
    "# client is the first 3 layer of total model\n",
    "client = torch.nn.Sequential(*list(t_model().children())[:3])\n",
    "print(client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
