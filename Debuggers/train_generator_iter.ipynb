{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do not need to generator 32 channels together. One way is to generate them \n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, inputsize, hiddensize, outputsize):\n",
    "        super(Generator, self).__init__()\n",
    "        self.inputsize = inputsize # 8, 16, 24\n",
    "        self.outputsize = outputsize\n",
    "        self.hiddensize = hiddensize\n",
    "        self.section1 = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(self.inputsize, hiddensize * 8, 3, 1, padding=1, bias=False, dilation=1),\n",
    "            nn.BatchNorm2d(hiddensize * 8),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.section2 = nn.Sequential(\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(hiddensize * 8, hiddensize * 4, 3, 1, padding=1 , bias=False, dilation=1),\n",
    "            nn.BatchNorm2d(hiddensize * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(hiddensize * 4, hiddensize * 2, 3, 1, padding=1, bias=False, dilation=1),\n",
    "            nn.BatchNorm2d(hiddensize * 2),\n",
    "            nn.ReLU(True),\n",
    "            # # state size. (ngf*2) x 16 x 16\n",
    "            # nn.ConvTranspose2d(hiddensize * 2, hiddensize, 4, 1, 0, bias=False),\n",
    "            # nn.BatchNorm2d(hiddensize),\n",
    "            # nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(hiddensize * 2, self.outputsize, 3, 1, padding=1, bias=False, dilation=1),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.section1(input)\n",
    "        output = self.section2(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Total Accuracy  0.8284\n"
     ]
    }
   ],
   "source": [
    "# use the client and server for mobilenetv2\n",
    "import torch\n",
    "from Models.mobilenetv2 import mobilenetv2_splitter, MobileNetV2\n",
    "client, server = mobilenetv2_splitter(num_classes = 10, \n",
    "                                      weight_root = '/home/tonypeng/Workspace1/adaptfilter/Adaptfilter/Weights/cifar-10', \n",
    "                                      device = 'cuda:0', \n",
    "                                      partition = -1)\n",
    "model = MobileNetV2(num_classes = 10)\n",
    "model.load_state_dict(torch.load('/home/tonypeng/Workspace1/adaptfilter/Adaptfilter/Weights/cifar-10/pretrained/mobilenetv2.pth'))\n",
    "# get the dataloader \n",
    "from Dataloaders import dataloader_cifar10\n",
    "train, test, classes = dataloader_cifar10.Dataloader_cifar10()\n",
    "\n",
    "client = client.to('cuda:0')\n",
    "server = server.to('cuda:0')\n",
    "model = model.to('cuda:0')\n",
    "client.eval()\n",
    "server.eval()\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    correct2 = 0\n",
    "    for i, data in enumerate(test, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to('cuda:0'), labels.to('cuda:0')\n",
    "        outputs = client(inputs)\n",
    "        outputs = server(outputs)\n",
    "        outputs2 = model(inputs)\n",
    "        outputs = torch.argmax(outputs, dim = 1)\n",
    "        outputs2 = torch.argmax(outputs2, dim = 1)\n",
    "        correct_rate = (outputs == labels).sum().item()\n",
    "        correct_rate2 = (outputs2 == labels).sum().item()\n",
    "        correct += correct_rate\n",
    "        correct2 += correct_rate2\n",
    "    print('Total Accuracy ', correct/10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a squeeze layer to the model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class depressor(nn.Module):\n",
    "    def __init__(self, inputsize, outputsize):\n",
    "        # ex input 16, output 4\n",
    "        super().__init__()\n",
    "        self.inputsize = inputsize\n",
    "        self.outputsize = outputsize\n",
    "        self.section1 = nn.Sequential(\n",
    "            nn.Conv2d(self.inputsize, self.outputsize, 3, 1, padding = 1),\n",
    "            nn.BatchNorm2d(self.outputsize),\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        output = self.section1(input)\n",
    "        return output\n",
    "# https://github.com/Lornatang/CGAN-PyTorch/blob/master/cgan_pytorch/models/generator.py\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, image_size: int = 28, channels: int = 1, num_channels: int = 32):\n",
    "        # ex input 4, output 1\n",
    "        super().__init__()\n",
    "        self.image_size = image_size\n",
    "        self.channels = channels\n",
    "\n",
    "        self.label_embedding = nn.Embedding(num_channels, num_channels)\n",
    "        self.input_size = self.image_size[0] * self.image_size[1]\n",
    "        self.input_size += num_channels\n",
    "        self.output_size = self.image_size[0] * self.image_size[1]\n",
    "        \n",
    "        self.pre = nn.Sequential(\n",
    "            nn.Conv2d(self.input_size, self.input_size//2, 3, 1, padding=1),\n",
    "            nn.BatchNorm2d(self.input_size//2),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(self.input_size//2, 1, 3, 1, padding=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "        )\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.input_size, 2*self.input_size),\n",
    "            nn.BatchNorm1d(2*self.input_size),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(2*self.input_size, 4*self.input_size),\n",
    "            nn.BatchNorm1d(4*self.input_size),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(4*self.input_size, self.input_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor, labels: list = None) -> torch.Tensor:\n",
    "\n",
    "        conditional_inputs = torch.cat([inputs, self.label_embedding(labels)], dim=-1)\n",
    "        out = self.main(conditional_inputs)\n",
    "        out = out.reshape(self.image_size, self.image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "?block\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "prod(): argument 'input' (position 1) must be Tensor, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m test[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,:,:] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     43\u001b[0m test[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mget_zero_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# for epoch in range(10):\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#     running_loss = 0.0\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#     for i, data in enumerate(train, 0):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m         \u001b[38;5;66;03m# get zeros\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 28\u001b[0m, in \u001b[0;36mget_zero_rank\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_zero_rank\u001b[39m(\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# input is torch\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     inputsize \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# 4*4\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     zero_rate \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;66;03m# b,c\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     zero_rank \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;66;03m# b,c\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: prod(): argument 'input' (position 1) must be Tensor, not int"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import client and server\n",
    "from Models.mobilenetv2 import mobilenetv2_splitter, MobileNetV2\n",
    "client, server = mobilenetv2_splitter(num_classes = 10, weight_root='/home/tonypeng/Workspace1/adaptfilter/Adaptfilter/Weights/cifar-10', device='cuda:0', partition=-1)\n",
    "from Dataloaders import dataloader_cifar10\n",
    "train, test, classes = dataloader_cifar10.Dataloader_cifar10()\n",
    "client = client.to('cuda:0')\n",
    "server = server.to('cuda:0')\n",
    "client.eval()\n",
    "server.eval()\n",
    "\n",
    "depress = depressor(16, 4)\n",
    "depress = depress.to('cuda:0')\n",
    "depress.train()\n",
    "\n",
    "generator = Generator(image_size=[112,112])\n",
    "generator = generator.to('cuda:0')\n",
    "generator.train()\n",
    "\n",
    "import torch.optim as optim\n",
    "criterion = nn.L1Loss()\n",
    "d_optimizer = optim.SGD(depress.parameters(), lr=0.001, momentum=0.9)\n",
    "g_optimizer = optim.SGD(generator.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "print('?block')\n",
    "import numpy as np\n",
    "def get_zero_rank(input):\n",
    "    # input is torch\n",
    "    inputsize = torch.prod(input.size(2) * input.size(3))# 4*4\n",
    "    zero_rate = torch.zeros(input.shape[:2]) # b,c\n",
    "    zero_rank = torch.zeros(input.shape[:2]) # b,c\n",
    "    for i, c in enumerate(input):\n",
    "        for j in range(input[i].shape[0]): # c\n",
    "            zeros = torch.where(input[i,j,:,:]==0, 1, 0)\n",
    "            zero_rate[i,j] = torch.sum(zeros)/inputsize\n",
    "            if zero_rate[i,j] > 0.5:\n",
    "                zero_rate[i,j] = 1\n",
    "        # sort the zeros rate\n",
    "        zero_rank[i] = torch.argsort(zero_rate) # descend \n",
    "    return zero_rank\n",
    "\n",
    "test = torch.zeros(2,3,4,4)\n",
    "test[0,0,:,:] = 1\n",
    "test[0,1,:,0:3] = 1\n",
    "print(get_zero_rank(test))\n",
    "# for epoch in range(10):\n",
    "#     running_loss = 0.0\n",
    "#     for i, data in enumerate(train, 0):\n",
    "#         inputs, labels = data\n",
    "#         inputs, labels = inputs.to('cuda:0'), labels.to('cuda:0')\n",
    "#         outputs = client(inputs)\n",
    "\n",
    "        # get zeros\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 0, 1],\n",
      "        [0, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def get_zero_rank(input):\n",
    "    # input is torch\n",
    "    inputsize = input.size(2) * input.size(3)# 4*4\n",
    "    zero_rate = torch.zeros(input.shape[:2]) # b,c\n",
    "    zero_rank = torch.zeros(input.shape[:2]) # b,c\n",
    "    for i, c in enumerate(input):\n",
    "        for j in range(input[i].shape[0]): # c\n",
    "            zeros = torch.where(input[i,j,:,:]==0, 1, 0)\n",
    "            zero_rate[i,j] = torch.sum(zeros)/inputsize\n",
    "            if zero_rate[i,j] > 0.5:\n",
    "                zero_rate[i,j] = 1\n",
    "        # sort the zeros rate\n",
    "    zero_rank = torch.argsort(zero_rate) # descend \n",
    "        \n",
    "    return zero_rank\n",
    "test = torch.zeros(2,3,4,4)\n",
    "test[0,2,:,:] = 1\n",
    "test[0,0,:,0:3] = 1\n",
    "print(get_zero_rank(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 5, 6],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3],[4,5,6]])\n",
    "b = torch.tensor([1, 0])\n",
    "a[b,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
