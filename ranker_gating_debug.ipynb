{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# this is the first version ranker\\n# first, load the embeddings\\n# stored in torch tensors\\n\\nimport torch\\nimport numpy as np\\nimport os\\nimport sys\\nimport json\\nimport argparse\\nimport time\\nimport random\\nimport torch.nn as nn\\nimport torch.optim as optim\\nfrom torch.autograd import Variable\\nimport scipy.stats \\n\\nembeddings_folder = '../data/cifar-10-embedding-3/embeddings/' \\nembeddings_files = sorted(os.listdir(embeddings_folder))\\ntest_embeddings = torch.load(embeddings_folder + embeddings_files[0]) # load the first file\\nprint(test_embeddings.size()) # 128, 32, 32, 32\\n\\n# calculate the entropy of the embeddings, select 1%, 5%, 10%, 20%, 50% of the embeddings\\ndef calculate_entropy(embs, percentage):\\n    # embs are torch tensors\\n    # percentage shows the number of embeddings to select\\n    embs_entropy = []\\n    for i in range(embs.size(len(embs.size())-3)):\\n        embs_entropy.append(scipy.stats.entropy(embs[:, i].reshape(-1))) # b, c\\n    # get the top percentage of the channels\\n    embs_entropy = np.array(embs_entropy)\\n    indices = np.argsort(embs_entropy)\\n    num_selected = int(embs.size(1) * percentage)\\n    selected_indices = indices[:num_selected]\\n    return selected_indices\\n    # out b, c*p, h, w or c*p, h, w\\n\\ndef ranker_entropy(embs, percentage):\\n    # calculate the entropy of the embeddings\\n    selected_indices = calculate_entropy(embs, percentage)\\n    # select indice from test embeddings\\n    selected_embeddings = embs[:, selected_indices] # b, c*p, h, w\\n    return selected_embeddings\\n\\n# get the selected embeddings\\nselected_embeddings = ranker_entropy(test_embeddings, 0.1)\\nprint(selected_embeddings.size())\\n\\n# design a simple gating mechanism for regression\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# this is the first version ranker\n",
    "# first, load the embeddings\n",
    "# stored in torch tensors\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import scipy.stats \n",
    "\n",
    "embeddings_folder = '../data/cifar-10-embedding-3/embeddings/' \n",
    "embeddings_files = sorted(os.listdir(embeddings_folder))\n",
    "test_embeddings = torch.load(embeddings_folder + embeddings_files[0]) # load the first file\n",
    "print(test_embeddings.size()) # 128, 32, 32, 32\n",
    "\n",
    "# calculate the entropy of the embeddings, select 1%, 5%, 10%, 20%, 50% of the embeddings\n",
    "def calculate_entropy(embs, percentage):\n",
    "    # embs are torch tensors\n",
    "    # percentage shows the number of embeddings to select\n",
    "    embs_entropy = []\n",
    "    for i in range(embs.size(len(embs.size())-3)):\n",
    "        embs_entropy.append(scipy.stats.entropy(embs[:, i].reshape(-1))) # b, c\n",
    "    # get the top percentage of the channels\n",
    "    embs_entropy = np.array(embs_entropy)\n",
    "    indices = np.argsort(embs_entropy)\n",
    "    num_selected = int(embs.size(1) * percentage)\n",
    "    selected_indices = indices[:num_selected]\n",
    "    return selected_indices\n",
    "    # out b, c*p, h, w or c*p, h, w\n",
    "\n",
    "def ranker_entropy(embs, percentage):\n",
    "    # calculate the entropy of the embeddings\n",
    "    selected_indices = calculate_entropy(embs, percentage)\n",
    "    # select indice from test embeddings\n",
    "    selected_embeddings = embs[:, selected_indices] # b, c*p, h, w\n",
    "    return selected_embeddings\n",
    "\n",
    "# get the selected embeddings\n",
    "selected_embeddings = ranker_entropy(test_embeddings, 0.1)\n",
    "print(selected_embeddings.size())\n",
    "\n",
    "# design a simple gating mechanism for regression\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import scipy.stats \n",
    "\n",
    "def calculate_entropy(embs, percentage):\n",
    "    # embs are torch tensors\n",
    "    # percentage shows the number of embeddings to select\n",
    "    embs_entropy = []\n",
    "    for i in range(embs.size(len(embs.size())-3)):\n",
    "        embs_entropy.append(scipy.stats.entropy(embs[:, i].reshape(-1))) # b, c\n",
    "    # get the top percentage of the channels\n",
    "    embs_entropy = np.array(embs_entropy)\n",
    "    indices = np.argsort(embs_entropy)\n",
    "    num_selected = int(embs.size(1) * percentage)\n",
    "    selected_indices = indices[:num_selected]\n",
    "    return selected_indices\n",
    "    # out b, c*p, h, w or c*p, h, w\n",
    "\n",
    "def ranker_entropy(embs, percentage):\n",
    "    # calculate the entropy of the embeddings\n",
    "    selected_indices = calculate_entropy(embs, percentage)\n",
    "    # select indice from test embeddings\n",
    "    selected_embeddings = embs[:, selected_indices] # b, c*p, h, w\n",
    "    return selected_embeddings, selected_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import scipy.stats\n",
    "import torch.utils \n",
    "import os\n",
    "from Models import mobilenetv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 32, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [10,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [13,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [14,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [15,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [17,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [20,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [22,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [24,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [25,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [26,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [27,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [30,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [31,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 121\u001b[0m\n\u001b[1;32m    119\u001b[0m outputs \u001b[38;5;241m=\u001b[39m Gated(selected_embeddings)\n\u001b[1;32m    120\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m--> 121\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m], Step [\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_loader), loss\u001b[38;5;241m.\u001b[39mitem()))\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/torch/autograd/__init__.py:259\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    250\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    251\u001b[0m     (inputs,)\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (torch\u001b[38;5;241m.\u001b[39mTensor, graph\u001b[38;5;241m.\u001b[39mGradientEdge))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[1;32m    256\u001b[0m )\n\u001b[1;32m    258\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[0;32m--> 259\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/torch/autograd/__init__.py:142\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    136\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    137\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for real scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m         )\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[1;32m    141\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 142\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# import the server model\n",
    "run_device = 'tintin'\n",
    "# This is the version 1 gated regression model, we need a simpler version\n",
    "# class GatedRegression(nn.Module):\n",
    "#     def __init__(self, input_size, num_classes):\n",
    "#         super(GatedRegression, self).__init__()\n",
    "#         # think about it 3*32*32 -> 1\n",
    "#         # think about the classification of the mobile net\n",
    "#         self.input_size = input_size\n",
    "#         self.num_classes = num_classes\n",
    "#         self.hidden_size = input_size\n",
    "#         self.conv1 = nn.Conv2d(input_size, 2*self.hidden_size, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(2*self.hidden_size)\n",
    "#         self.conv2 = nn.Conv2d(2*self.hidden_size, 4*self.hidden_size, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "#         self.bn2 = nn.BatchNorm2d(4*self.hidden_size)\n",
    "#         self.conv3 = nn.Conv2d(4*self.hidden_size, 8*self.hidden_size, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "#         self.bn3 = nn.BatchNorm2d(8*self.hidden_size)\n",
    "#         self.linear = nn.Linear(8*self.hidden_size, num_classes)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.avgpool = nn.AvgPool2d(4)\n",
    "#         self.flatten = nn.Flatten(start_dim=1, end_dim=-1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # need to change 32 -> 4\n",
    "#         out = self.conv1(x)\n",
    "#         out = self.bn1(out)\n",
    "#         out = self.conv2(out)\n",
    "#         out = self.bn2(out)\n",
    "#         out = self.conv3(out)\n",
    "#         out = self.bn3(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.avgpool(out)\n",
    "#         out = self.flatten(out)\n",
    "#         out = self.linear(out)\n",
    "#         return out\n",
    "\n",
    "class GatedRegression(nn.Module):\n",
    "    def __init__(self, input_size, weight, height):\n",
    "        super(GatedRegression, self).__init__()\n",
    "        # think about it 3*32*32 -> 1\n",
    "        # think about the classification of the mobile net\n",
    "        # the input size is b, c*p, h, w, the output size is b \n",
    "        # how to make sure more features help the server model?\n",
    "\n",
    "        self.input_size = input_size * weight * height\n",
    "        self.structure = [self.input_size, self.input_size//weight, self.input_size//height//weight, 1]\n",
    "        self.linear1 = nn.Linear(self.structure[0], self.structure[1])\n",
    "        self.linear2 = nn.Linear(self.structure[1], self.structure[2])\n",
    "        self.linear3 = nn.Linear(self.structure[2], self.structure[3])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.flatten = nn.Flatten(start_dim=1, end_dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # need to change it to 0-1\n",
    "        # flatten the input first\n",
    "        out = self.flatten(x)\n",
    "        out = self.linear1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "\n",
    "# load the dataset\n",
    "class gated_dataset(torch.utils.data.Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self, embeddings_folder):\n",
    "        self.embeddings_folder = embeddings_folder\n",
    "        self.embeddings_files = sorted(os.listdir(embeddings_folder+'/embeddings/'))\n",
    "        self.labels_files = sorted(os.listdir(embeddings_folder+'/labels/'))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.embeddings_files.__len__()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx == 0:\n",
    "            self.embeddings = torch.load(self.embeddings_folder+'/embeddings/' + self.embeddings_files[idx])\n",
    "            self.labels = torch.load(self.embeddings_folder+'/labels/' + self.labels_files[idx])\n",
    "        else:\n",
    "            self.embeddings = torch.cat((self.embeddings, torch.load(embeddings_folder+'/embeddings/' + self.embeddings_files[idx])), 0)\n",
    "            self.labels = torch.cat((self.labels, torch.load(embeddings_folder+'/labels/' + self.labels_files[idx])), 0)\n",
    "        return self.embeddings, self.labels\n",
    "    \n",
    "# load the dataset\n",
    "if run_device == 'tintin':\n",
    "    embeddings_folder = '/data/anp407/cifar-10-embedding-3/'\n",
    "if run_device == 'server':\n",
    "    embeddings_folder = '../data/cifar-10-embedding-3/'\n",
    "dataset = gated_dataset(embeddings_folder)\n",
    "# print(gated_dataset.__len__(dataset)) # 391 batches                                             \n",
    "\n",
    "# load the data loader, train no test\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# load the model\n",
    "Gated = GatedRegression(input_size=3, weight=32, height=32)\n",
    "Gated = Gated.cuda()\n",
    "Gated.train()\n",
    "\n",
    "# get the server model\n",
    "client_model, server_model = mobilenetv2.stupid_model_splitter(weight_path='./Weights/cifar-10/MobileNetV2.pth')\n",
    "server_model = server_model.cuda()\n",
    "server_model.eval()\n",
    "# load the optimizer\n",
    "optimizer = optim.Adam(Gated.parameters(), lr=0.001)\n",
    "\n",
    "# load the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# train the model\n",
    "for epoch in range(100):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        embs, labels = data\n",
    "        # for the training, embeddings doesn't need to be on the cuda\n",
    "        # embs, labels = embs.cuda(), labels.cuda()\n",
    "        labels = labels.cuda()\n",
    "        # embeddings = Variable(embeddings) # what are they?\n",
    "        # labels = Variable(labels) # what are they?\n",
    "        embs = embs.squeeze(0)\n",
    "        labels = labels.squeeze(0)\n",
    "        s_embs, s_inds = ranker_entropy(embs, 0.1)\n",
    "        s_embs = s_embs.cuda()\n",
    "        # make the embeddings to fit the server model\n",
    "        n_embs = torch.zeros(s_embs.size(0), 32, 32, 32)\n",
    "        n_embs[:, s_inds] = s_embs\n",
    "        n_embs = n_embs.cuda()\n",
    "\n",
    "        # get the output from the server model\n",
    "        with torch.no_grad():\n",
    "            outputs = server_model(n_embs)\n",
    "\n",
    "        outputs = Gated(selected_embeddings)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' % (epoch+1, 10, i+1, len(train_loader), loss.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
