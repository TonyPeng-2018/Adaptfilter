{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: cifar-10, model: mobilenetV2, gated: True, ranker: entropy, generator: False, gatename: GateMLP, threshold: 0.6, test_batch: 100\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:09, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average confidence is:  0.8452839583158493\n",
      "The average confidence for each gate is: 0.8392, 0.8452, 0.8515, 0.8291\n",
      "The average accuracy is:  91.96\n",
      "Gate chosen: 1, 36, 46, 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# this is the total pipeline for the project\n",
    "# This file is for trainning\n",
    "# Run this on the server, or as we called offline. \n",
    "\n",
    "# with gated, no generator\n",
    "from Dataloaders.dataloader_cifar10 import Dataloader_cifar10\n",
    "import argparse\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "from Models import mobilenetv2\n",
    "from Utils import utils\n",
    "from Models import gatedmodel\n",
    "from Models import generator\n",
    "from tqdm import tqdm\n",
    "\n",
    "def main(args):\n",
    "    \"\"\"\n",
    "    # initial using mobilenetV2, and cifar10\n",
    "    # we need a if statement here to decide which model and dataset to use\n",
    "    # random_seed = 2024\n",
    "\n",
    "    # for training, it is for training the generator \n",
    "    # recall the graph, when we cut more features, the performance should be worse.\n",
    "    \n",
    "    # get the training loader, freeze the model. Where is the partitioning point? \n",
    "    \"\"\"\n",
    "\n",
    "    # 1. get the train, test and val datasets, and labels.\n",
    "    if args.dataset == 'cifar-10':\n",
    "        # return train, test, val, labels, these are all dataloaders\n",
    "        _, test, classes = Dataloader_cifar10(train_batch=128, test_batch=args.tb, seed=2024)\n",
    "    elif args.dataset == 'cifar-100':\n",
    "        pass\n",
    "    \n",
    "    # 2. transfer the dataset to fit the model, for the training, client and server model are all on the server\n",
    "    if args.model == 'mobilenetV2':\n",
    "        client, server = mobilenetv2.stupid_model_splitter(weight_path='./Weights/cifar-10/model/MobileNetV2.pth')\n",
    "    elif args.model == 'resnet':\n",
    "        pass\n",
    "\n",
    "    # 3. get the gating, gating here decides how many channels are transferred to the server\n",
    "    # simple version: a binary tree, complex version: model\n",
    "    # get a ranker to rank the channels, and get the top k channels\n",
    "    ranker = utils.ranker_entropy # input: embs, percentage, output: s_emb, s_ind\n",
    "\n",
    "    # 4. get the gated model, we have 3 models here\n",
    "    gate_name = args.gatename\n",
    "    gated_rates = [0.25, 0.5, 0.75]\n",
    "    channel2ind = {8:0, 16:1, 24:2, 32:3}\n",
    "    input_channel = 32\n",
    "    gateds = []\n",
    "    for i in range(3):\n",
    "        gateds.append(gatedmodel.model_list[gate_name](\n",
    "            input_size=int(input_channel*gated_rates[i]),\n",
    "            width=32,\n",
    "            height=32,\n",
    "            output_size=1)) #  input_size, weight, height, output_size=10\n",
    "        # s_time = utils.get_latest_weights(args.dataset, gate_name, 'gate')\n",
    "        # s_time = ('_').join(['0']*6)+'.pth'\n",
    "        s_time = '2024_06_14_17_46_36'\n",
    "        gateds[i].load_state_dict(torch.load('./Weights/'+args.dataset+'/gate/'+s_time+'/'+gate_name+'_'+str(i)+'_'+s_time+'.pth'))\n",
    "\n",
    "    # 5. get the generator\n",
    "    generators = []\n",
    "    for i in range(3):\n",
    "        generators.append(generator.Generator(\n",
    "            inputsize=int(input_channel*gated_rates[i]), \n",
    "            hiddensize=32, \n",
    "            outputsize=32)) # inputsize, hiddensize, outputsize\n",
    "    \"\"\"\n",
    "    # 6. get the server \n",
    "    # server = some_model_function()\n",
    "    # server model is got above\n",
    "\n",
    "    # pipline data -> dataloader -> client -> gating -> reducer -> generator -> server\n",
    "    \n",
    "    # cuda may not have enough space for putting all the models\n",
    "    # client = client.cuda()\n",
    "    # server = server.cuda()\n",
    "    # for i in range(3):\n",
    "    #     gateds[i] = gateds[i].cuda()\n",
    "    #     generators[i] = generators[i].cuda() \"\"\"  \n",
    "\n",
    "    # set them to eval\n",
    "    client.eval()\n",
    "    server.eval()\n",
    "    for i in range(3):\n",
    "        gateds[i].eval()\n",
    "        generators[i].eval()\n",
    "\n",
    "    # load the test data set the test\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        t_conf = 0 # total confidence\n",
    "        t_zero = 0 # total number of 0\n",
    "        c_gate = [0]*4\n",
    "        f_gate = [0]*4\n",
    "        client = client.cuda()\n",
    "        server = server.cuda()\n",
    "        for i, data in tqdm(enumerate(test)):\n",
    "            images, labels = data\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            # first, run the client model on the iot\n",
    "            out = client(images)\n",
    "            # calcualte the total number of 0\n",
    "            # t_zero += torch.sum(out == 0).item()/32/32/32\n",
    "            # second, run the ranker\n",
    "            ex_flag = args.gated\n",
    "            ex_gate = 0\n",
    "            # print('The number of 0 in the tensor is: ', torch.sum(out == 0).item())\n",
    "            # if the exit_flag is a True\n",
    "            if type(ex_flag) == bool:\n",
    "                while ex_flag:\n",
    "                    # get the emb and ind from the ranker\n",
    "                    out = out.cpu()\n",
    "                    s_emb, s_ind = ranker(out, gated_rates[ex_gate])\n",
    "                    s_emb = s_emb.cuda()\n",
    "                    # give it to the gated model\n",
    "                    cur_gated = gateds[ex_gate].cuda() # b,e',h,w -> b,1 (softmax value)\n",
    "                    g_conf = torch.mean(cur_gated(s_emb)).item() # b, n\n",
    "                    # print('The confidence is: ', g_conf)\n",
    "                    l_thres = args.threshold * np.exp(ex_flag*1/3)\n",
    "                    if g_conf > l_thres:\n",
    "                        ex_flag = not ex_flag\n",
    "                    else:\n",
    "                        ex_gate += 1\n",
    "\n",
    "                    if ex_gate == 3:\n",
    "                        break\n",
    "                # check the exit flag and send\n",
    "                if ex_flag != args.gated:\n",
    "                    # print('The choosen gate is: ', ex_gate)\n",
    "                    out = s_emb\n",
    "\n",
    "            # if the exit_flag is a number\n",
    "            elif type(ex_flag) == int:\n",
    "                out = out.cpu()\n",
    "                s_emb, s_ind = ranker(out, gated_rates[ex_flag])\n",
    "                s_emb = s_emb.cuda()\n",
    "                cur_gated = gateds[ex_flag].cuda()\n",
    "                g_conf = torch.mean(cur_gated(s_emb)).item() # b, n\n",
    "                # print('The confidence is: ', g_conf.item())\n",
    "                out = s_emb # b, c, h, w\n",
    "                # print the number of 0 in the tensor)\n",
    "                # print('The number of 0 in the tensor is: ', torch.sum(out == 0).item())\n",
    "                # return 0\n",
    "\n",
    "            # a sender here, but on server, we don't have it.\n",
    "            \n",
    "            # a receiver here, but on server, we don't have it.\n",
    "            t_conf += g_conf\n",
    "            c_gate[ex_gate] += 1\n",
    "            f_gate[ex_gate] += g_conf\n",
    "            # get the generator\n",
    "            rec_size = out.size(1)\n",
    "            # print('The size of the tensor is: ', rec_size)\n",
    "            if ex_flag != args.gated or type(args.gated) == int: # int !=\n",
    "                rec_ind = s_ind\n",
    "            rec_size2ind = channel2ind[rec_size]\n",
    "            # if we don't get all features, we need to use the generator\n",
    "            if args.generator:\n",
    "                if rec_size2ind != 3:\n",
    "                    cur_gen = generators[rec_size2ind]\n",
    "                    # load weights\n",
    "                    cur_gen.load_state_dict(torch.load('./Weights/cifar-10/generator/generator_'+str(rec_size2ind)+'.pth'))\n",
    "                    cur_gen = cur_gen.cuda()\n",
    "                    out = cur_gen(out)\n",
    "\n",
    "            # skip the generator, create a tensor with all zeros\n",
    "            else:\n",
    "                if ex_flag != args.gated or type(args.gated) == int:\n",
    "                    n_out = torch.zeros(out.size(0), 32, 32, 32).cuda()\n",
    "                    n_out[:, rec_ind, :, :] = out\n",
    "                    out = n_out\n",
    "            # run the server model\n",
    "            out = out.cuda()\n",
    "            out = server(out)\n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "        print('The average confidence is: ', 100 * t_conf/total)\n",
    "        print('The average confidence for each gate is: %.4f, %.4f, %.4f, %.4f' % (f_gate[0]/max(c_gate[0], 1), \\\n",
    "                                                                             f_gate[1]/max(c_gate[1], 1), f_gate[2]/max(c_gate[2], 1), f_gate[3]/max(c_gate[3], 1)))\n",
    "        print('The average accuracy is: ', 100 * correct / total)\n",
    "        # print('The average number of 0 is: ', t_zero/total)   \n",
    "        print('Gate chosen: %d, %d, %d, %d' % (c_gate[0], c_gate[1], c_gate[2], c_gate[3]))\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     print('enter')\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     # we need the name of model, the name of dataset\n",
    "#     parser.add_argument('--dataset', type=str, default='cifar10', help='name of dataset')\n",
    "#     # parser.add_argument('--iot_model', type=str, default='mobilenetV2', help='name of the model on the iot')\n",
    "#     parser.add_argument('--reducer', type=str, default='entrophy', help='name of the reducer')\n",
    "#     parser.add_argument('--client', type=str, default='LTE', help='name of the network condition on the client side')\n",
    "#     parser.add_argument('--server', type=str, default='LTE', help='name of the network condition on the server side')\n",
    "#     parser.add_argument('--generator', type=str, default='None', help='name of the generator')\n",
    "#     # parser.add_argument('--server', type=str, default='mobilenetV2', help='name of the model on the server, should be the same as it on the iot')\n",
    "#     parser.add_argument('--device', type=str, default='home', help='run on which device, home, tintin, rpi, pico, jetson?')\n",
    "#     parser.add_argument('--model', type=str, default='mobilenetV2', help='name of the model')\n",
    "#     args = parser.parse_args()\n",
    "#     main(args)\n",
    "\n",
    "class custom_args:\n",
    "    def __init__(self):\n",
    "        self.dataset = 'cifar-10'\n",
    "        self.model = 'mobilenetV2'\n",
    "        self.gated = True\n",
    "        self.gatename = 'GateMLP'\n",
    "        self.ranker = 'entropy'\n",
    "        self.generator = False\n",
    "        self.threshold = 0.6\n",
    "        self.tb = 100\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'dataset: '+self.dataset+', model: '+self.model+', gated: '+str(self.gated)+', ranker: '+self.ranker+', generator: '+str(self.generator) \\\n",
    "            + ', gatename: '+self.gatename + ', threshold: '+str(self.threshold) + ', test_batch: '+str(self.tb)\n",
    "\n",
    "args = custom_args()\n",
    "print(args)\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1.weight',\n",
       "              tensor([[-0.0119, -0.0055, -0.0026,  ..., -0.0123, -0.0007, -0.0031],\n",
       "                      [ 0.0092, -0.0060, -0.0047,  ..., -0.0119, -0.0115, -0.0130],\n",
       "                      [-0.0097, -0.0155, -0.0152,  ..., -0.0007, -0.0081, -0.0029],\n",
       "                      ...,\n",
       "                      [-0.0099, -0.0155, -0.0089,  ...,  0.0029,  0.0028, -0.0094],\n",
       "                      [-0.0064, -0.0034,  0.0038,  ...,  0.0067,  0.0045, -0.0117],\n",
       "                      [-0.0043, -0.0164, -0.0147,  ..., -0.0147,  0.0012, -0.0130]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear1.bias',\n",
       "              tensor([ 4.8422e-03,  4.0539e-03, -1.3591e-02,  9.9373e-04, -1.6840e-02,\n",
       "                      -1.2041e-03, -1.3823e-02,  5.2071e-03,  2.7350e-03,  1.3404e-03,\n",
       "                      -1.0567e-02, -6.7861e-04, -5.1796e-05,  4.4697e-03, -5.3810e-03,\n",
       "                      -1.1258e-02, -2.0388e-03, -1.5965e-02,  5.2826e-03,  1.7817e-03,\n",
       "                      -3.9550e-03,  9.7604e-06, -1.0585e-03,  5.0008e-03, -9.1039e-03,\n",
       "                      -4.6688e-03, -1.1370e-03, -1.6005e-02, -2.2595e-03, -1.1767e-03,\n",
       "                       4.9383e-03,  7.2536e-03, -1.2003e-02,  4.1146e-03,  2.3119e-03,\n",
       "                      -8.2873e-03, -3.2043e-04, -5.2605e-03, -7.4109e-03,  2.4717e-03,\n",
       "                       4.7453e-03,  3.0359e-04, -1.4838e-02, -1.2283e-02, -1.4332e-02,\n",
       "                       3.3152e-03, -1.5011e-03, -7.5016e-03, -1.1288e-02,  3.7478e-03,\n",
       "                      -6.9996e-03,  5.0355e-03, -1.1306e-02, -2.7608e-03,  9.0741e-04,\n",
       "                       1.9948e-03, -5.6231e-03,  3.9771e-03, -7.9052e-03,  6.0634e-03,\n",
       "                       3.0734e-03, -1.0155e-02,  1.8917e+00,  3.5933e-03,  1.0091e-03,\n",
       "                       6.7022e-04, -2.5286e-03,  1.9901e-03, -1.3120e-02, -1.4620e-02,\n",
       "                      -1.3189e-02, -1.6395e-03, -1.5526e-03,  5.6422e-03,  1.7428e+00,\n",
       "                      -1.6598e-03, -9.4867e-04, -2.8040e-03, -1.1838e-02, -1.1367e-02,\n",
       "                      -1.2664e-02, -1.1958e-02, -9.4380e-03,  2.1674e-04,  3.0331e-04,\n",
       "                      -3.6762e-03, -4.6445e-03, -3.3720e-03, -1.5093e-02, -1.0765e-02,\n",
       "                       4.3107e-03,  1.7975e+00,  5.6363e-03, -1.0194e-02, -7.1173e-03,\n",
       "                      -1.2120e-02,  1.9335e+00,  3.0138e-03, -1.3697e-02, -5.9546e-03,\n",
       "                       1.9201e-03,  2.2399e-03, -5.1475e-03,  1.2686e-03, -8.0084e-03,\n",
       "                      -8.9701e-03, -3.2140e-03, -1.1493e-02,  8.2713e-03, -5.2314e-03,\n",
       "                      -1.3212e-02, -1.2700e-02, -8.8180e-03, -1.5009e-03, -1.3143e-02,\n",
       "                      -1.4609e-02, -2.2550e-03, -4.1932e-03, -7.8342e-03, -1.2284e-02,\n",
       "                      -7.2622e-03,  3.6288e-03,  6.2821e-03, -1.3040e-03, -1.4027e-02,\n",
       "                      -1.2687e-02, -8.4247e-03,  1.8592e+00,  4.6924e-03, -1.4291e-03,\n",
       "                      -4.5398e-03, -6.0667e-03, -1.1312e-02, -4.8266e-03, -1.4716e-02,\n",
       "                      -1.4702e-02, -4.2755e-03, -4.4626e-03,  2.1160e-03,  2.9469e-03,\n",
       "                       3.3580e-04, -1.0430e-02,  4.3356e-03, -6.4511e-03, -4.8591e-03,\n",
       "                      -1.1299e-02,  1.6417e-03, -3.6540e-03, -8.4445e-03, -5.9863e-03,\n",
       "                      -4.3007e-03, -5.7677e-03, -3.6675e-04, -1.0516e-02,  3.6098e-03,\n",
       "                       8.8860e-04,  6.0719e-04,  6.4828e-03,  4.6220e-03,  4.0836e-03,\n",
       "                      -1.2700e-02,  3.3072e-03,  5.6244e-04,  8.2029e-04, -4.2371e-03,\n",
       "                       5.6196e-03, -7.2602e-03, -1.0600e-02, -9.9940e-03,  1.7238e+00,\n",
       "                      -2.7812e-03, -1.1120e-02, -7.1326e-04,  3.6444e-03,  1.7818e-03,\n",
       "                      -1.2534e-02, -1.0523e-02,  4.0832e-03, -1.2804e-02, -4.9981e-03,\n",
       "                      -7.1227e-03, -8.5938e-03, -4.5351e-03, -1.2293e-02, -2.7403e-03,\n",
       "                      -1.2857e-02, -2.0921e-03,  5.2055e-03, -1.3816e-02, -1.3960e-02,\n",
       "                       3.8128e-03, -1.7984e-03,  3.4617e-03, -3.6542e-03, -7.0147e-03,\n",
       "                      -1.5821e-03, -5.3536e-03, -7.2392e-03, -1.5742e-02, -6.4950e-04,\n",
       "                      -6.1437e-03, -1.4332e-02, -8.6452e-03, -1.4459e-02, -1.2007e-02,\n",
       "                      -1.0641e-02,  3.0481e-03, -5.4407e-03, -1.2280e-02, -1.3707e-02,\n",
       "                       4.9632e-03,  2.0688e+00, -1.3204e-02, -1.0482e-02,  4.5257e-03,\n",
       "                      -7.3139e-03, -1.0421e-02,  4.6042e-03, -3.7277e-04, -2.6573e-03,\n",
       "                      -6.4452e-03,  6.1260e-03, -8.5800e-03, -1.0419e-03,  7.8138e-04,\n",
       "                       2.5321e-03, -2.8820e-03,  4.3812e-03, -2.8672e-03, -1.4875e-02,\n",
       "                      -6.8748e-04, -5.3348e-03,  5.6475e-04, -8.8014e-03,  1.4885e-03,\n",
       "                      -6.7004e-03,  1.7788e-03, -1.5068e-02, -3.0229e-03,  4.4578e-03,\n",
       "                      -1.2369e-03, -2.7688e-03, -9.5526e-03,  5.5564e-03, -4.6032e-03,\n",
       "                      -6.4821e-03, -4.9429e-03, -6.9790e-03,  4.3136e-03, -7.2282e-03,\n",
       "                      -1.3544e-02, -2.0321e-03,  1.8154e-03, -2.2701e-03, -6.9515e-03,\n",
       "                      -1.4977e-02], device='cuda:0')),\n",
       "             ('linear2.weight',\n",
       "              tensor([[ 7.4346e-03, -5.4275e-02,  1.8274e-02, -2.4074e-02, -1.3243e-02,\n",
       "                        2.4779e-02, -2.7371e-03,  5.7144e-02,  1.2043e-02,  4.0065e-02,\n",
       "                        1.2038e-02,  2.5815e-02, -4.0937e-02,  4.0039e-03,  3.7983e-02,\n",
       "                        3.7454e-02, -4.0176e-02, -4.5114e-02,  5.0918e-02, -2.7893e-02,\n",
       "                       -6.8262e-03,  3.2892e-04, -1.6106e-02, -3.1982e-02,  2.0267e-02,\n",
       "                       -1.5520e-02, -1.6070e-02, -3.7887e-02,  1.9640e-02,  5.5554e-02,\n",
       "                        1.8493e-02,  5.5050e-02,  8.4684e-04,  3.9890e-02,  3.3527e-03,\n",
       "                       -4.4722e-02, -3.3664e-02, -1.9985e-02,  5.9037e-03, -5.2867e-02,\n",
       "                        3.3237e-03, -5.2361e-02, -2.5836e-02,  5.6931e-03, -3.8313e-02,\n",
       "                       -5.0977e-02,  2.9676e-02, -2.6381e-02, -2.3803e-02, -2.0109e-03,\n",
       "                       -3.8657e-02, -4.1616e-02, -5.1571e-02,  8.2812e-03, -3.3064e-02,\n",
       "                       -5.6326e-02,  3.3241e-02,  1.6857e-02,  3.8334e-02,  1.0783e-02,\n",
       "                        3.2285e-02,  3.9198e-02,  1.6157e-02,  3.9631e-02,  4.8741e-02,\n",
       "                        5.3702e-02,  1.6227e-02,  4.3601e-03,  5.3734e-02, -1.5029e-02,\n",
       "                        2.4902e-02, -2.6101e-02,  5.6180e-02,  2.7367e-02,  1.5050e-02,\n",
       "                       -2.5666e-02, -1.0014e-03,  1.9887e-04, -6.5308e-03, -1.3807e-02,\n",
       "                        3.9804e-02,  8.8642e-03, -5.4582e-02,  2.8720e-02,  2.9785e-02,\n",
       "                        4.6709e-02,  3.1520e-02, -5.4256e-02,  3.0689e-02,  3.2612e-02,\n",
       "                       -8.3412e-03,  1.4964e-02,  3.4225e-02, -1.3630e-02, -2.0026e-02,\n",
       "                       -2.8850e-02,  1.6614e-02, -3.1898e-02,  3.1465e-02,  5.1659e-03,\n",
       "                        4.8764e-03,  5.7030e-02,  1.8763e-02,  1.4181e-02,  7.1127e-05,\n",
       "                       -4.5222e-02, -3.9221e-02,  4.9566e-02,  4.8958e-02, -3.7939e-02,\n",
       "                        3.5205e-02,  3.0089e-04, -5.8182e-04,  1.0571e-02, -3.5782e-02,\n",
       "                       -3.5897e-02,  1.1614e-02,  1.9854e-02,  7.4231e-03,  3.5580e-02,\n",
       "                        2.7918e-03,  3.0449e-02,  6.4480e-03,  3.3304e-02, -1.3265e-03,\n",
       "                       -5.3470e-02,  4.3290e-03,  1.6420e-02,  4.4991e-02,  2.2029e-02,\n",
       "                        2.7120e-03, -1.3621e-02,  5.4957e-02, -1.2006e-02,  1.0459e-02,\n",
       "                        4.4271e-02, -4.6344e-02,  5.9849e-03,  1.2479e-02,  5.2654e-02,\n",
       "                        1.7013e-02, -1.4245e-02,  3.9373e-03,  7.9034e-03, -3.9022e-03,\n",
       "                        3.8205e-02,  1.1395e-02, -4.5283e-03, -3.1206e-02,  3.9404e-02,\n",
       "                       -2.3136e-02, -5.7687e-03,  4.8418e-02,  1.9946e-03,  1.1460e-02,\n",
       "                        3.6813e-02,  5.0297e-02, -2.4934e-03, -2.1831e-02,  9.0533e-03,\n",
       "                        2.1161e-02,  4.2152e-02,  2.6250e-02,  1.7025e-02, -1.4375e-02,\n",
       "                        1.2204e-03,  2.5632e-02, -1.8747e-02,  1.2454e-02,  1.4129e-02,\n",
       "                        2.1896e-02, -5.4586e-02, -2.7700e-02,  2.7328e-02, -3.4826e-03,\n",
       "                        1.6348e-02, -1.3959e-02,  2.3827e-02,  1.5235e-03, -4.4657e-03,\n",
       "                       -3.8020e-02, -2.6076e-02, -8.5697e-03, -2.2444e-04,  3.4698e-03,\n",
       "                       -2.4051e-03,  4.3257e-02,  5.6264e-02, -3.9314e-02, -2.0986e-02,\n",
       "                       -1.9531e-02,  2.2394e-02,  3.8165e-02,  2.7317e-02,  3.5367e-02,\n",
       "                        5.4561e-02,  3.1569e-02, -4.1172e-02, -4.4401e-02,  1.1587e-02,\n",
       "                        2.6164e-03, -3.8304e-02,  2.4701e-02,  1.5069e-02,  4.2564e-02,\n",
       "                        3.6742e-02, -4.2232e-03,  5.1917e-02,  7.2855e-03,  3.7071e-03,\n",
       "                        4.4719e-03,  1.5589e-02,  1.2126e-02, -2.7643e-02,  4.6377e-02,\n",
       "                        3.5664e-02,  1.7325e-02, -3.0434e-02, -1.6090e-02,  1.2705e-02,\n",
       "                       -1.8328e-02,  4.1772e-02,  5.6434e-02,  3.9396e-02, -5.5125e-02,\n",
       "                       -9.4622e-03,  4.1908e-02, -2.9890e-02,  3.5811e-03, -4.2545e-02,\n",
       "                       -8.5123e-03, -2.5752e-02, -1.6029e-02, -1.9335e-03,  2.8654e-02,\n",
       "                        1.2214e-03, -1.6463e-02, -4.4492e-02, -5.1771e-02, -1.3982e-02,\n",
       "                       -1.5704e-02, -3.3954e-03,  1.9115e-02, -4.0396e-03,  1.4101e-02,\n",
       "                        3.6335e-02, -4.2580e-02, -1.7461e-02, -1.6348e-02, -4.3422e-02,\n",
       "                       -4.8075e-02,  2.0372e-02,  9.3521e-04,  5.7038e-03,  1.1522e-02,\n",
       "                        3.7728e-03]], device='cuda:0'))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the gate weight\n",
    "weightpath = '/home/tonypeng/Workspace1/adaptfilter/Adaptfilter/Weights/cifar-10/gate/2024_06_14_17_46_36/GateMLP_0_2024_06_14_17_46_36.pth'\n",
    "import torch\n",
    "torch.load(weightpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
