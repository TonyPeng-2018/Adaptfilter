{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for resnet50_client:\n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([64, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 3, 7, 7]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mModels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resnet\n\u001b[1;32m      4\u001b[0m weightpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/tonypeng/Workspace1/adaptfilter/Adaptfilter/Weights/cifar-10/model/ResNet50.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m client, server \u001b[38;5;241m=\u001b[39m \u001b[43mresnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstupid_model_splitter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweightpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mModels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mobilenetv2\n\u001b[1;32m      8\u001b[0m weightpath2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/tonypeng/Workspace1/adaptfilter/Adaptfilter/Weights/cifar-10/model/MobileNetV2.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/Workspace1/adaptfilter/Adaptfilter/Models/resnet.py:436\u001b[0m, in \u001b[0;36mstupid_model_splitter\u001b[0;34m(num_classes, weight_path, device)\u001b[0m\n\u001b[1;32m    434\u001b[0m     client_model_keys \u001b[38;5;241m=\u001b[39m client_model\u001b[38;5;241m.\u001b[39mstate_dict()\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m    435\u001b[0m     client_weights \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m client_weights\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m client_model_keys}\n\u001b[0;32m--> 436\u001b[0m     \u001b[43mclient_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;66;03m# create server, load the weights and filter the client\u001b[39;00m\n\u001b[1;32m    439\u001b[0m server_model \u001b[38;5;241m=\u001b[39m resnet50_server(block \u001b[38;5;241m=\u001b[39m Bottleneck, layers \u001b[38;5;241m=\u001b[39mlayers, num_classes \u001b[38;5;241m=\u001b[39m num_classes)\n",
      "File \u001b[0;32m~/anaconda3/envs/iot/lib/python3.12/site-packages/torch/nn/modules/module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2184\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2185\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2186\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2190\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for resnet50_client:\n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([64, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 3, 7, 7])."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "\n",
    "def Dataloader_cifar100(train_batch=128, test_batch=100, seed=2024, val_set = False, datasetpath = '/home/tonypeng/Workspace1/adaptfilter/data/'):\n",
    "    torch.manual_seed(seed)\n",
    "    transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    trainset = torchvision.datasets.CIFAR100(\n",
    "        root=datasetpath, train=True, transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=train_batch, shuffle=True, num_workers=4)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR100(\n",
    "        root=datasetpath, train=False, transform=transform_test)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=test_batch, shuffle=False, num_workers=4)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "            'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    return trainloader, testloader, classes\n",
    "\n",
    "def Dataloader_cifar100_val(train_batch=128, test_batch=100, seed=2024, datasetpath = '/home/tonypeng/Workspace1/adaptfilter/data/'):\n",
    "   \n",
    "    torch.manual_seed(seed)\n",
    "    transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=datasetpath, train=True, transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=train_batch, shuffle=True, num_workers=4)\n",
    "    # split the training set into training and validation set\n",
    "    trainset, valset = torch.utils.data.random_split(trainset, [40000, 10000])\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=train_batch, shuffle=False, num_workers=4)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=datasetpath, train=False, transform=transform_test)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=test_batch, shuffle=False, num_workers=4)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "            'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    return trainloader, testloader, valloader, classes\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train, test, classes = Dataloader_cifar100(train_batch=128, test_batch=100, seed=2024)\n",
    "    for i, data in enumerate(train):\n",
    "        inputs, labels = data\n",
    "        break\n",
    "    # print the size of each loader\n",
    "    print(len(train))\n",
    "    print(len(test))\n",
    "    print('done')\n",
    "\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    # get 10 pictures from testloader, and the labels\n",
    "    for i, data in enumerate(test):\n",
    "        images, labels = data\n",
    "    \n",
    "    # print the image and label\n",
    "    print('label1: ', classes[labels[0]])\n",
    "    # print image\n",
    "    img = images[0]\n",
    "    img = img.numpy()\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
