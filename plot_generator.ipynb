{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "tensor([7, 4, 0, 9, 4, 1, 3, 3, 7, 7, 1, 1, 7, 3, 4, 9, 0, 9, 4, 0, 9, 3, 9, 8,\n",
      "        7, 9, 1, 0, 9, 9, 4, 7, 9, 0, 9, 1, 3, 1, 3, 8, 8, 0, 7, 1, 6, 3, 7, 2,\n",
      "        4, 6, 9, 8, 3, 1, 7, 8, 7, 1, 3, 6, 0, 8, 0, 7, 1, 9, 7, 1, 3, 2, 1, 3,\n",
      "        4, 1, 7, 9, 0, 7, 1, 7, 7, 3, 3, 9, 1, 9, 1, 2, 4, 1, 8, 7, 8, 7, 8, 2,\n",
      "        3, 3, 5, 7, 8, 3, 8, 1, 3, 8, 2, 0, 0, 7, 0, 1, 8, 8, 5, 7, 9, 3, 4, 7,\n",
      "        1, 9, 3, 3, 2, 7, 7, 7], device='cuda:0')\n",
      "tensor([2, 6, 3, 1, 2, 0, 6, 2, 4, 5, 1, 1, 5, 8, 5, 9, 0, 9, 2, 0, 8, 3, 2, 0,\n",
      "        7, 1, 1, 8, 8, 1, 3, 5, 9, 8, 8, 9, 5, 1, 3, 8, 8, 0, 5, 1, 6, 6, 4, 2,\n",
      "        7, 6, 1, 8, 7, 1, 3, 3, 9, 1, 3, 6, 0, 8, 0, 9, 9, 0, 7, 1, 4, 6, 1, 2,\n",
      "        2, 1, 2, 9, 0, 1, 1, 5, 3, 3, 6, 9, 1, 7, 1, 3, 3, 9, 0, 7, 0, 4, 0, 4,\n",
      "        3, 2, 5, 7, 9, 7, 1, 3, 5, 8, 6, 0, 0, 5, 0, 9, 8, 8, 5, 3, 1, 6, 2, 5,\n",
      "        2, 9, 3, 5, 4, 6, 7, 5], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# the generator used the part of features to make all data\n",
    "# We suppose that it is a GAN, DCGAN\n",
    "\n",
    "from Dataloaders import dataloader_cifar10\n",
    "import datetime\n",
    "from Models import mobilenetv2, mobilenetv3, resnet, generator, encoder_client\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from Utils import utils\n",
    "\n",
    "in_ch = 32\n",
    "g_rate = [0.4]\n",
    "# logger\n",
    "stime = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "logger = utils.APLogger('./Logs/train_generator_' + stime + '.log')\n",
    "logger.write('Dataset: CIFAR-10\\n, Model: mobilenetv2\\n, Generator: GeneratorV1\\n, Encoder: 2layerCNN\\n, Batch: 128\\n, Epochs: 100\\n, Seed: 2024\\n')\n",
    "logger.write('Rate: %.1f\\n'%g_rate[0])\n",
    "\n",
    "# client, and server model\n",
    "client_model, server_model = mobilenetv2.mobilenetv2_splitter(num_classes=10, weight_root='./Weights/cifar-10/', partition=-1)\n",
    "client_model.eval()\n",
    "server_model.eval()\n",
    "client_model = client_model.to('cuda:0')\n",
    "server_model = server_model.to('cuda:0')\n",
    "# for param in client_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in server_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# dataloader using the \n",
    "train, _, val = dataloader_cifar10.Dataloader_cifar10_val(train_batch=128, test_batch=100, seed=2024)\n",
    "\n",
    "# we have 3 generators for 3 discriminators\n",
    "Generators = []\n",
    "\n",
    "for i in range(len(g_rate)):\n",
    "    Generators.append(generator.Generator(int(in_ch*g_rate[i]), hiddensize=32, outputsize=32).cuda())\n",
    "    Generators[i] = Generators[i].cuda()\n",
    "\n",
    "Encoders = []\n",
    "for i in range(len(g_rate)):\n",
    "    Encoders.append(encoder_client.Encoder_Client(in_ch=in_ch, out_ch=int(g_rate[i]*in_ch)).cuda())\n",
    "    Encoders[i] = Encoders[i].cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.cuda()\n",
    "\n",
    "\n",
    "for i in range (len(Generators)):\n",
    "\n",
    "    netG = Generators[i]\n",
    "    netG.load_state_dict(torch.load('/home/tonypeng/Workspace1/adaptfilter/Adaptfilter/Weights/cifar-10/generator/generator_0.4_2024_07_08_03_17_07.pth'))\n",
    "    netG = netG.cuda()\n",
    "\n",
    "    netE = Encoders[i]\n",
    "    netE.load_state_dict(torch.load('/home/tonypeng/Workspace1/adaptfilter/Adaptfilter/Weights/cifar-10/encoder/encoder_0.4_2024_07_08_03_17_07.pth'))\n",
    "    netE = netE.cuda()\n",
    "\n",
    "    netG.eval()\n",
    "    netE.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for j, data in enumerate(val):\n",
    "            img, label = data\n",
    "            img, label = img.cuda(), label.cuda()\n",
    "            \n",
    "            out = client_model(img).detach()\n",
    "            \n",
    "            out_max = torch.max(out)\n",
    "            out_min = torch.min(out)\n",
    "\n",
    "            out = (out - out_min) / (out_max - out_min)\n",
    "\n",
    "            # train the encoder\n",
    "            out = netE(out)\n",
    "            # train the generator\n",
    "            out = netG(out)\n",
    "\n",
    "            out = out * (out_max - out_min) + out_min\n",
    "            # train the encoder            \n",
    "            out = server_model(out)\n",
    "            out = torch.argmax(out, dim=1)\n",
    "            # change it to float\n",
    "            print(out)\n",
    "            print(label)\n",
    "            break\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "127\n",
      "Time: 0.0030\n",
      "Time2: 0.0028\n"
     ]
    }
   ],
   "source": [
    "# the generator used the part of features to make all data\n",
    "# We suppose that it is a GAN, DCGAN\n",
    "\n",
    "from Dataloaders import dataloader_cifar10, dataloader_imagenet\n",
    "import datetime\n",
    "from Models import mobilenetv2, mobilenetv3, resnet, generator, encoder_client\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "import time\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from Utils import utils\n",
    "\n",
    "in_ch = 32\n",
    "g_rate = [0.6]\n",
    "# logger\n",
    "stime = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "logger = utils.APLogger('./Logs/train_generator_' + stime + '.log')\n",
    "logger.write('Dataset: CIFAR-10\\n, Model: mobilenetv2\\n, Generator: GeneratorV1\\n, Encoder: 2layerCNN\\n, Batch: 128\\n, Epochs: 100\\n, Seed: 2024\\n')\n",
    "logger.write('Rate: %.1f\\n'%g_rate[0])\n",
    "\n",
    "# client, and server model\n",
    "client_model, server_model = mobilenetv2.mobilenetv2_splitter(num_classes=10, weight_root='./Weights/cifar-10/', partition=-1)\n",
    "# client_model, server_model = mobilenetv2.mobilenetv2_splitter(num_classes=1000, weight_root='./Weights/imagenet/', partition=-1)\n",
    "client_model.eval()\n",
    "server_model.eval()\n",
    "client_model = client_model.to('cuda:0')\n",
    "server_model = server_model.to('cuda:0')\n",
    "# for param in client_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in server_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# dataloader using the \n",
    "train, _, val = dataloader_cifar10.Dataloader_cifar10_val(train_batch=128, test_batch=100, seed=2024)\n",
    "# train, _, val, _ = dataloader_imagenet.Dataloader_imagenet_integrated()\n",
    "\n",
    "# we have 3 generators for 3 discriminators\n",
    "Generators = []\n",
    "\n",
    "for i in range(len(g_rate)):\n",
    "    Generators.append(generator.Generator(int(in_ch*g_rate[i]), hiddensize=32, outputsize=32).cuda())\n",
    "    Generators[i] = Generators[i].cuda()\n",
    "\n",
    "Encoders = []\n",
    "for i in range(len(g_rate)):\n",
    "    Encoders.append(encoder_client.Encoder_Client(in_ch=in_ch, out_ch=int(g_rate[i]*in_ch)).cuda())\n",
    "    Encoders[i] = Encoders[i].cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.cuda()\n",
    "\n",
    "\n",
    "for i in range (len(Generators)):\n",
    "\n",
    "    netG = Generators[i]\n",
    "    # netG.load_state_dict(torch.load('/home/tonypeng/Workspace1/adaptfilter/Adaptfilter/Weights/cifar-10/generator/generator_0.6_2024_07_08_03_51_38.pth'))\n",
    "    netG = netG.cuda()\n",
    "\n",
    "    netE = Encoders[i]\n",
    "    # netE.load_state_dict(torch.load('/home/tonypeng/Workspace1/adaptfilter/Adaptfilter/Weights/cifar-10/encoder/encoder_0.6_2024_07_08_03_51_38.pth'))\n",
    "    netE = netE.cuda()\n",
    "\n",
    "    netG.eval()\n",
    "    netE.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_time = 0\n",
    "        total_time2 = 0\n",
    "\n",
    "        for j, data in enumerate(val):\n",
    "            imgs, labels = data\n",
    "            for k in range (imgs.size(0)):\n",
    "                img, label = imgs[k], labels[k]\n",
    "                img = img.unsqueeze(0)\n",
    "                label = label.unsqueeze(0)\n",
    "                img, label = img.cuda(), label.cuda()\n",
    "                \n",
    "                out = client_model(img).detach()\n",
    "                \n",
    "                out_max = torch.max(out)\n",
    "                out_min = torch.min(out)\n",
    "\n",
    "                out = (out - out_min) / (out_max - out_min)\n",
    "\n",
    "                # train the encoder\n",
    "                out = netE(out)\n",
    "                # train the generator\n",
    "                time1 = time.time()\n",
    "                out = netG(out)\n",
    "\n",
    "                out = out * (out_max - out_min) + out_min\n",
    "                # train the encoder\n",
    "                # time1 = time.time()            \n",
    "                out = server_model(out)\n",
    "                out = torch.argmax(out, dim=1)\n",
    "                time2 = time.time()\n",
    "                total_time += time2 - time1\n",
    "                # change it to float\n",
    "\n",
    "                time1 = time.time()\n",
    "                out = client_model(img).detach()\n",
    "                out = server_model(out)\n",
    "                out = torch.argmax(out, dim=1)\n",
    "                time2 = time.time()\n",
    "                total_time2 += time2 - time1\n",
    "            break\n",
    "        print(k)\n",
    "print('Time: %.4f'%(total_time / (k+1)))\n",
    "print('Time2: %.4f'%(total_time2 / (k+1)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
