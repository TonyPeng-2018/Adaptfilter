{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 226.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar-10 mobilenet\n",
      "0.8240985870361328, 1.9571852684020996, 2.882969379425049, 3.5321617126464844, 4.309632778167725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# this file is for device on the client side\n",
    "\n",
    "# load the dataset\n",
    "\n",
    "# This file is for trainning\n",
    "# Run this on the server, or as we called offline. \n",
    "\n",
    "import argparse\n",
    "import base64\n",
    "import cv2\n",
    "import datetime\n",
    "from Models import gatedmodel,mobilenetv2, resnet\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import psutil\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from Utils import utils, encoder\n",
    "\n",
    "middle_sizes_mobile = [1,2,4,8,16]\n",
    "middle_sizes_resnet = [1,2,4,8,16,32]\n",
    "\n",
    "middle_sizes = {'mobilenet': middle_sizes_mobile, 'resnet': middle_sizes_resnet}\n",
    "reduced_sizes = {'cifar-10': (32,32), 'imagenet': (224,224)}\n",
    "reduced_rates = {'mobilenet': 2, 'resnet': 4}\n",
    "\n",
    "dataset = 'cifar-10'\n",
    "model = 'mobilenet'\n",
    "i_stop = 100\n",
    "\n",
    "width, height = reduced_sizes[dataset][0]/reduced_rates[model], \\\n",
    "                reduced_sizes[dataset][1]/reduced_rates[model]\n",
    "middle_size = middle_sizes[model]\n",
    "\n",
    "# client include client, middle and gate\n",
    "\n",
    "client = mobilenetv2.mobilenetv2_splitter_client(num_classes = 10, weight_root='./Weights/'+dataset+'/', device='cpu')\n",
    "# client = resnet.resnet_splitter_client(num_classes=1000, weight_root='./Weights/'+dataset+'/', device='cpu', layers=50)\n",
    "\n",
    "middle_models = []\n",
    "for i in range(len(middle_size)):\n",
    "    middle_models.append(mobilenetv2.MobileNetV2_middle(middle=middle_size[i]))\n",
    "    # middle_models.append(resnet.resnet_middle(middle=middle_size[i]))\n",
    "\n",
    "gate_models = []\n",
    "for i in range(len(middle_size)):\n",
    "    gate_models.append(gatedmodel.ExitGate(in_planes=middle_size[i],\n",
    "                                           height = height, width=width))\n",
    "\n",
    "# eval\n",
    "client.eval()\n",
    "for i in range(len(middle_size)):\n",
    "    middle_models[i].eval()\n",
    "    gate_models[i].eval()\n",
    "\n",
    "# quantize\n",
    "client = torch.ao.quantization.quantize_dynamic(client, {torch.nn.Linear, torch.nn.Conv2d}, dtype=torch.qint8)\n",
    "for i in range(len(middle_size)):\n",
    "    middle_models[i] = torch.ao.quantization.quantize_dynamic(middle_models[i], {torch.nn.Linear, torch.nn.Conv2d}, dtype=torch.qint8)\n",
    "    gate_models[i] = torch.ao.quantization.quantize_dynamic(gate_models[i], {torch.nn.Linear, torch.nn.Conv2d}, dtype=torch.qint8)\n",
    "\n",
    "# 2. dataset\n",
    "# directly read bmp image from the storage\n",
    "data_root = '../data/'+dataset+'-client/'\n",
    "data_client_out = []\n",
    "for i in range(len(middle_size)):\n",
    "    data_client_out.append('../data/'+dataset+'-'+model+'-client-'+str(middle_size[i])+'/')\n",
    "    if not os.path.exists(data_client_out[i]):\n",
    "        os.makedirs(data_client_out[i])\n",
    "    \n",
    "images_list = os.listdir(data_root)\n",
    "images_list.remove('labels.txt')\n",
    "# remove ending with jpg\n",
    "images_list = [x for x in images_list if x.endswith('.bmp')]\n",
    "images_list = sorted(images_list)\n",
    "\n",
    "client_time = [0] * len(middle_size)\n",
    "\n",
    "# this is test the overspeed, so we don't need to load the models\n",
    "with torch.no_grad():\n",
    "        for i, i_path in tqdm(enumerate(images_list)):\n",
    "            if i >= i_stop:\n",
    "                break\n",
    "            \n",
    "            image_path = data_root + i_path\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "            image = image.astype(np.float32)/255.0\n",
    "            image = torch.tensor(image)\n",
    "            image = image.unsqueeze(0)\n",
    "            image = image.permute(0, 3, 1, 2)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                s_time = time.time()\n",
    "                client_out = client(image).detach()\n",
    "                for j in range(len(middle_size)):\n",
    "                    middle_in = middle_models[j].in_layer(client_out)\n",
    "                    gate_out = gate_models[j](middle_in)\n",
    "                    middle_in = middle_in.squeeze(0)\n",
    "                    middle_int = utils.float_to_uint(middle_in)\n",
    "                    middle_int = middle_int.numpy().copy(order='C')\n",
    "                    middle_int = middle_int.astype(np.uint8)\n",
    "                    send_in = base64.b64encode(middle_int)\n",
    "                    # store it in the folder\n",
    "                    with open(data_client_out[j] + i_path[:-4], 'wb') as f:\n",
    "                        f.write(send_in)\n",
    "                    s1_time = time.time()\n",
    "                    client_time[j] += s1_time - s_time\n",
    "\n",
    "for i in range(len(client_time)):\n",
    "    client_time[i] /= i_stop / 1000 # ms per frame\n",
    "\n",
    "# print the list without [ and ]\n",
    "out_string = str(client_time).replace('[','').replace(']','')\n",
    "print(dataset, model)\n",
    "print(out_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a image and store it\n",
    "# image = cv2.imread('../data/imagenet-client/0.bmp', cv2.IMREAD_COLOR)\n",
    "# # encode\n",
    "# image = image.astype(np.uint8)\n",
    "# image = base64.b64encode(image)\n",
    "# # store\n",
    "# with open('../data/imagenet-client/0b', 'wb') as f:\n",
    "#     f.write(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "data_root = '../data/imagenet-client/'\n",
    "# get '.bmp'\n",
    "import os \n",
    "images_list = os.listdir(data_root)\n",
    "images_list = [x for x in images_list if x.endswith('.bmp')]\n",
    "\n",
    "data_out = '../data/imagenet-jpeg/'\n",
    "\n",
    "import cv2\n",
    "# compress the image jpeg\n",
    "for i_path in images_list:\n",
    "    image_path = data_root + i_path\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    for quality in range(5, 100, 5):\n",
    "        cv2.imwrite(data_out+i_path[:-4]+'_'+str(quality)+'.jpg', image, [int(cv2.IMWRITE_JPEG_QUALITY), quality])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/cifar-10-jpeg25/\n",
      "[0.65, 0.7, 0.6333333333333333, 0.6833333333333333, 0.65, 0.7, 0.7166666666666667, 0.6666666666666666, 0.7666666666666667, 0.7166666666666667]\n",
      "[3.321786721547445, 3.167839845021566, 3.113889694213867, 3.452531496683757, 3.3099611600240073, 3.1742294629414873, 3.095245361328125, 3.180229663848877, 3.098241488138835, 3.1754453976949053]\n",
      "../data/cifar-10-jpeg75/\n",
      "[0.8, 0.8666666666666667, 0.7666666666666667, 0.7833333333333333, 0.7166666666666667, 0.7666666666666667, 0.8333333333333334, 0.7666666666666667, 0.9, 0.8833333333333333]\n",
      "[3.245274225870768, 3.1121174494425454, 3.1221787134806314, 3.11356782913208, 3.1094511349995932, 3.129263718922933, 3.1371434529622397, 3.1410296758015948, 3.1263311703999834, 3.1348228454589844]\n",
      "../data/cifar-10-cjpeg/\n",
      "[0.8166666666666667, 0.8, 0.7666666666666667, 0.8166666666666667, 0.7166666666666667, 0.8, 0.8333333333333334, 0.7833333333333333, 0.8666666666666667, 0.8666666666666667]\n",
      "[3.190298875172933, 3.1914353370666504, 3.16008726755778, 3.1347155570983887, 3.1566341718037925, 3.152950604756673, 3.1710306803385415, 3.1833608945210776, 3.1502366065979004, 3.1615535418192544]\n"
     ]
    }
   ],
   "source": [
    "# load embbeded \n",
    "dataset = 'cifar-10'\n",
    "model = 'mobilenet'\n",
    "out_path = ['../data/'+dataset+'-jpeg25/', '../data/'+dataset+'-jpeg75/', '../data/'+dataset+'-cjpeg/']\n",
    "import torch\n",
    "from Models import mobilenetv2, resnet\n",
    "from torchvision import transforms\n",
    "import time\n",
    "import base64\n",
    "import numpy as np\n",
    "import cv2\n",
    "for opath in out_path:\n",
    "\n",
    "    \n",
    "    model = mobilenetv2.MobileNetV2(num_classes=10)\n",
    "    model.load_state_dict(torch.load('./Weights/'+dataset+'/pretrained/mobilenetv2.pth'))\n",
    "    model = model.to('cuda')\n",
    "    model.eval()\n",
    "\n",
    "    root_path = '../data/'+dataset+'-client/'\n",
    "    labels = root_path+'labels.txt'\n",
    "    labels = open(labels, 'r')\n",
    "    labels = labels.readlines()\n",
    "    labels = [x[:-1] for x in labels]\n",
    "    labels = torch.tensor([int(x) for x in labels])\n",
    "    labels\n",
    "\n",
    "    images = [str(x) for x in range(600)]\n",
    "    preds = []\n",
    "\n",
    "    \n",
    "    if dataset == 'cifar-10':\n",
    "        normal = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "    elif dataset == 'imagenet':\n",
    "        normal = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        server_time = []\n",
    "        for image in images:\n",
    "            \n",
    "            image_path = opath + image\n",
    "            i_read = open(image_path, 'rb')\n",
    "            image = i_read.read()\n",
    "            # decode\n",
    "            s_time = time.time()\n",
    "            image = base64.b64decode(image)\n",
    "            image = np.frombuffer(image, dtype=np.uint8)\n",
    "            image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "            image = normal(image)\n",
    "            image = image.unsqueeze(0)\n",
    "            image = image.to('cuda')\n",
    "            pred = model(image)\n",
    "            pred = torch.argmax(pred, dim=1)\n",
    "            preds.append(pred.item())\n",
    "            e_time = time.time()\n",
    "            server_time.append(e_time - s_time)\n",
    "\n",
    "    preds = torch.tensor(preds)\n",
    "    accuracy = [0] * 10 \n",
    "    server_time_box = [0] * 10\n",
    "    # calculate the accuracy every 60 frames\n",
    "    for i in range(0, 600, 60):\n",
    "        accuracy[i//60] = torch.sum(preds[i:i+60] == labels[i:i+60]).item() / 60\n",
    "        server_time_box[i//60] = sum(server_time[i:i+60]) / 60*1000\n",
    "\n",
    "    print(opath)\n",
    "    print(accuracy)\n",
    "    print(server_time_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/cifar-10-jpeg25-ML/\n",
      "[0.7333, 0.7333, 0.5667, 0.55, 0.6, 0.65, 0.7167, 0.6, 0.6833, 0.7167]\n",
      "[3.1158, 3.1078, 3.2164, 3.2086, 3.0422, 2.9906, 2.9844, 3.0055, 2.9925, 2.9831]\n",
      "../data/cifar-10-jpeg75-ML/\n",
      "[0.8167, 0.8167, 0.7333, 0.8167, 0.6667, 0.75, 0.75, 0.6833, 0.8167, 0.8833]\n",
      "[3.0094, 2.9996, 3.0027, 3.0042, 2.996, 2.9956, 3.0027, 2.9946, 3.0037, 3.0019]\n",
      "../data/cifar-10-cjpeg-ML/\n",
      "[0.7333, 0.85, 0.7167, 0.7, 0.7, 0.8167, 0.7, 0.75, 0.7667, 0.8333]\n",
      "[3.0358, 3.0187, 3.0196, 3.0213, 3.0209, 3.0359, 3.0335, 3.0569, 3.0195, 3.0334]\n"
     ]
    }
   ],
   "source": [
    "# load embbeded \n",
    "dataset = 'cifar-10'\n",
    "model = 'mobilenet'\n",
    "\n",
    "out_path = ['../data/'+dataset+'-jpeg25-ML/', '../data/'+dataset+'-jpeg75-ML/', '../data/'+dataset+'-cjpeg-ML/']\n",
    "import torch\n",
    "from Models import mobilenetv2, resnet\n",
    "from torchvision import transforms\n",
    "import time\n",
    "import base64\n",
    "import numpy as np\n",
    "import cv2\n",
    "for opath in out_path:\n",
    "\n",
    "    model = mobilenetv2.MobileNetV2(num_classes=10)\n",
    "    model.load_state_dict(torch.load('./Weights/'+dataset+'/pretrained/mobilenetv2.pth'))\n",
    "    model = model.to('cuda')\n",
    "    model.eval()\n",
    "\n",
    "    root_path = '../data/'+dataset+'-client/'\n",
    "    labels = root_path+'labels.txt'\n",
    "    labels = open(labels, 'r')\n",
    "    labels = labels.readlines()\n",
    "    labels = [x[:-1] for x in labels]\n",
    "    labels = torch.tensor([int(x) for x in labels])\n",
    "    labels\n",
    "\n",
    "    images = [str(x) for x in range(600)]\n",
    "    preds = []\n",
    "\n",
    "    from torchvision import transforms\n",
    "    if dataset == 'cifar-10':\n",
    "        normal = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "    elif dataset == 'imagenet':\n",
    "        normal = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        server_time = []\n",
    "        for image in images:\n",
    "            \n",
    "            image_path = opath + image\n",
    "            # check is the path exist\n",
    "            i_read = open(image_path, 'rb')\n",
    "            image = i_read.read()\n",
    "            \n",
    "            # decode\n",
    "            s_time = time.time()\n",
    "            image = base64.b64decode(image)\n",
    "            image = np.frombuffer(image, dtype=np.uint8)\n",
    "            image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "            image = normal(image)\n",
    "            image = image.unsqueeze(0)\n",
    "            image = image.to('cuda')\n",
    "            pred = model(image)\n",
    "            pred = torch.argmax(pred, dim=1)\n",
    "            preds.append(pred.item())\n",
    "            e_time = time.time()\n",
    "            server_time.append(e_time - s_time)\n",
    "\n",
    "    preds = torch.tensor(preds)\n",
    "    accuracy = [0] * 10 \n",
    "    server_time_box = [0] * 10\n",
    "    # calculate the accuracy every 60 frames\n",
    "    for i in range(0, 600, 60):\n",
    "        accuracy[i//60] = torch.sum(preds[i:i+60] == labels[i:i+60]).item() / 60\n",
    "        server_time_box[i//60] = sum(server_time[i:i+60]) / 60*1000\n",
    "\n",
    "    print(opath)\n",
    "    # change it to 4 float \n",
    "    for i in range(10):\n",
    "        accuracy[i] = float(str('%.4f'%accuracy[i]))\n",
    "        server_time_box[i] = float(str('%.4f'%server_time_box[i]))\n",
    "    print(accuracy)\n",
    "    print(server_time_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/imagenet-20-jpeg25-ML/\n",
      "[0.45, 0.4333, 0.4833, 0.3833, 0.4167, 0.45, 0.4, 0.5833, 0.55, 0.65]\n",
      "[5.3645, 4.9753, 5.3577, 5.3949, 5.6408, 5.4833, 5.6144, 5.8528, 5.0103, 5.2712]\n",
      "../data/imagenet-20-jpeg75-ML/\n",
      "[0.6667, 0.5833, 0.7167, 0.5833, 0.75, 0.7, 0.6833, 0.7, 0.75, 0.75]\n",
      "[5.7225, 5.2585, 5.5746, 5.5671, 5.8161, 5.5767, 5.8245, 6.0693, 5.3879, 5.6762]\n",
      "../data/imagenet-20-cjpeg-ML/\n",
      "[0.5833, 0.5, 0.6333, 0.5333, 0.6333, 0.6333, 0.6167, 0.6833, 0.6667, 0.7333]\n",
      "[7.1993, 6.7135, 7.0339, 7.1668, 7.3736, 7.011, 7.3398, 7.8842, 6.6181, 7.098]\n"
     ]
    }
   ],
   "source": [
    "# load embbeded \n",
    "dataset = 'imagenet-20'\n",
    "model = 'resnet'\n",
    "\n",
    "out_path = ['../data/'+dataset+'-jpeg25-ML/', '../data/'+dataset+'-jpeg75-ML/', '../data/'+dataset+'-cjpeg-ML/']\n",
    "import torch\n",
    "from Models import mobilenetv2, resnet\n",
    "from torchvision import transforms\n",
    "import time\n",
    "import base64\n",
    "import numpy as np\n",
    "import cv2\n",
    "for opath in out_path:\n",
    "\n",
    "    model = resnet.resnet50(num_classes=1000)\n",
    "    model.load_state_dict(torch.load('./Weights/'+'imagenet'+'/pretrained/resnet50.pth'))\n",
    "    model = model.to('cuda')\n",
    "    model.eval()\n",
    "\n",
    "    root_path = '../data/'+dataset+'-client/'\n",
    "    labels = root_path+'labels.txt'\n",
    "    labels = open(labels, 'r')\n",
    "    labels = labels.readlines()\n",
    "    labels = [x[:-1] for x in labels]\n",
    "    labels = torch.tensor([int(x) for x in labels])\n",
    "    labels\n",
    "\n",
    "    images = [str(x) for x in range(600)]\n",
    "    preds = []\n",
    "\n",
    "    from torchvision import transforms\n",
    "    if dataset == 'cifar-10':\n",
    "        normal = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "    elif dataset == 'imagenet-20':\n",
    "        normal = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        server_time = []\n",
    "        for image in images:\n",
    "            \n",
    "            image_path = opath + image\n",
    "            # check is the path exist\n",
    "            i_read = open(image_path, 'rb')\n",
    "            image = i_read.read()\n",
    "            \n",
    "            # decode\n",
    "            s_time = time.time()\n",
    "            image = base64.b64decode(image)\n",
    "            image = np.frombuffer(image, dtype=np.uint8)\n",
    "            image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "            image = normal(image)\n",
    "            image = image.unsqueeze(0)\n",
    "            image = image.to('cuda')\n",
    "            pred = model(image)\n",
    "            pred = torch.argmax(pred, dim=1)\n",
    "            preds.append(pred.item())\n",
    "            e_time = time.time()\n",
    "            server_time.append(e_time - s_time)\n",
    "\n",
    "    preds = torch.tensor(preds)\n",
    "    accuracy = [0] * 10 \n",
    "    server_time_box = [0] * 10\n",
    "    # calculate the accuracy every 60 frames\n",
    "    for i in range(0, 600, 60):\n",
    "        accuracy[i//60] = torch.sum(preds[i:i+60] == labels[i:i+60]).item() / 60\n",
    "        server_time_box[i//60] = sum(server_time[i:i+60]) / 60*1000\n",
    "\n",
    "    print(opath)\n",
    "    # change it to 4 float \n",
    "    for i in range(10):\n",
    "        accuracy[i] = float(str('%.4f'%accuracy[i]))\n",
    "        server_time_box[i] = float(str('%.4f'%server_time_box[i]))\n",
    "    print(accuracy)\n",
    "    print(server_time_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/imagenet-20-jpeg25/\n",
      "[0.7, 0.6667, 0.7333, 0.6667, 0.7333, 0.7333, 0.7667, 0.7167, 0.75, 0.8167]\n",
      "[5.312, 4.9395, 5.2042, 5.2532, 5.6307, 5.4263, 5.544, 5.6886, 5.0294, 5.3301]\n",
      "../data/imagenet-20-jpeg75/\n",
      "[0.7333, 0.7333, 0.75, 0.7833, 0.7833, 0.85, 0.9, 0.8, 0.8, 0.8833]\n",
      "[5.7784, 5.3921, 5.6901, 5.6746, 5.697, 5.4954, 5.7028, 5.9074, 5.7537, 5.5621]\n",
      "../data/imagenet-20-cjpeg/\n",
      "[0.7667, 0.7667, 0.7833, 0.8, 0.8667, 0.8333, 0.9167, 0.8167, 0.7833, 0.85]\n",
      "[7.1461, 6.7674, 7.1299, 7.2767, 7.5804, 7.4747, 7.6563, 8.4955, 7.1995, 7.4197]\n"
     ]
    }
   ],
   "source": [
    "# load embbeded \n",
    "dataset = 'imagenet-20'\n",
    "model = 'resnet'\n",
    "\n",
    "out_path = ['../data/'+dataset+'-jpeg25/', '../data/'+dataset+'-jpeg75/', '../data/'+dataset+'-cjpeg/']\n",
    "import torch\n",
    "from Models import mobilenetv2, resnet\n",
    "from torchvision import transforms\n",
    "import time\n",
    "import base64\n",
    "import numpy as np\n",
    "import cv2\n",
    "for opath in out_path:\n",
    "\n",
    "    model = resnet.resnet50(num_classes=1000)\n",
    "    model.load_state_dict(torch.load('./Weights/'+'imagenet'+'/pretrained/resnet50.pth'))\n",
    "    model = model.to('cuda')\n",
    "    model.eval()\n",
    "\n",
    "    root_path = '../data/'+dataset+'-client/'\n",
    "    labels = root_path+'labels.txt'\n",
    "    labels = open(labels, 'r')\n",
    "    labels = labels.readlines()\n",
    "    labels = [x[:-1] for x in labels]\n",
    "    labels = torch.tensor([int(x) for x in labels])\n",
    "    labels\n",
    "\n",
    "    images = [str(x) for x in range(600)]\n",
    "    preds = []\n",
    "\n",
    "    from torchvision import transforms\n",
    "    if dataset == 'cifar-10':\n",
    "        normal = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            ])\n",
    "    elif dataset == 'imagenet-20':\n",
    "        normal = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        server_time = []\n",
    "        for image in images:\n",
    "            \n",
    "            image_path = opath + image\n",
    "            # check is the path exist\n",
    "            i_read = open(image_path, 'rb')\n",
    "            image = i_read.read()\n",
    "            \n",
    "            # decode\n",
    "            s_time = time.time()\n",
    "            image = base64.b64decode(image)\n",
    "            image = np.frombuffer(image, dtype=np.uint8)\n",
    "            image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "            image = normal(image)\n",
    "            image = image.unsqueeze(0)\n",
    "            image = image.to('cuda')\n",
    "            pred = model(image)\n",
    "            pred = torch.argmax(pred, dim=1)\n",
    "            preds.append(pred.item())\n",
    "            e_time = time.time()\n",
    "            server_time.append(e_time - s_time)\n",
    "\n",
    "    preds = torch.tensor(preds)\n",
    "    accuracy = [0] * 10 \n",
    "    server_time_box = [0] * 10\n",
    "    # calculate the accuracy every 60 frames\n",
    "    for i in range(0, 600, 60):\n",
    "        accuracy[i//60] = torch.sum(preds[i:i+60] == labels[i:i+60]).item() / 60\n",
    "        server_time_box[i//60] = sum(server_time[i:i+60]) / 60*1000\n",
    "\n",
    "    print(opath)\n",
    "    # change it to 4 float \n",
    "    for i in range(10):\n",
    "        accuracy[i] = float(str('%.4f'%accuracy[i]))\n",
    "        server_time_box[i] = float(str('%.4f'%server_time_box[i]))\n",
    "    print(accuracy)\n",
    "    print(server_time_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/cifar-10-mobile-gate-emb/\n",
      "[0.8333, 0.8667, 0.7833, 0.8333, 0.8, 0.8167, 0.85, 0.8167, 0.85, 0.9]\n",
      "[5.2649, 3.0527, 3.2189, 3.5748, 3.0986, 3.2618, 3.383, 3.2862, 3.0711, 3.1564]\n"
     ]
    }
   ],
   "source": [
    "# load embbeded \n",
    "dataset = 'cifar-10'\n",
    "model = 'mobile'\n",
    "\n",
    "out_path = ['../data/cifar-10-mobile-gate-emb/']\n",
    "\n",
    "import torch\n",
    "from Models import mobilenetv2, resnet\n",
    "from torchvision import transforms\n",
    "import time\n",
    "import base64\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "for opath in out_path:\n",
    "\n",
    "    _, server = mobilenetv2.mobilenetv2_splitter(num_classes=10, weight_root='./Weights/'+dataset+'/')\n",
    "    server = server.to('cuda')\n",
    "    server.eval()\n",
    "\n",
    "    root_path = '../data/'+'cifar-10'+'-client/'\n",
    "    labels = root_path+'labels.txt'\n",
    "    labels = open(labels, 'r')\n",
    "    labels = labels.readlines()\n",
    "    labels = [x[:-1] for x in labels]\n",
    "    labels = torch.tensor([int(x) for x in labels])\n",
    "\n",
    "    images = [str(x) for x in range(600)]\n",
    "    preds = []\n",
    "\n",
    "    middle_sizes = [1,2,4,8,16]\n",
    "    middles = []\n",
    "    for i in range(len(middle_sizes)):\n",
    "        middles.append(mobilenetv2.MobileNetV2_middle(middle=middle_sizes[i]))\n",
    "        middles[i].load_state_dict(torch.load('./Weights/'+dataset+'/middle/mobile_cifar-10_middle_'+str(middle_sizes[i])+'.pth'))\n",
    "        middles[i] = middles[i].to('cuda')\n",
    "        middles[i].eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        server_time = []\n",
    "        for image in images:\n",
    "            \n",
    "            image_path = opath + image\n",
    "            # check is the path exist\n",
    "            i_read = open(image_path, 'rb')\n",
    "            img = i_read.read()\n",
    "            \n",
    "            # decode\n",
    "            s_time = time.time()\n",
    "            img = base64.b64decode(img)\n",
    "            img = np.frombuffer(img, dtype=np.uint8)\n",
    "            image_len = len(img)\n",
    "            image_c = int(image_len/16/16)\n",
    "            img = img.reshape(image_c, 16, 16)\n",
    "            img = torch.tensor(img)\n",
    "            img = img.unsqueeze(0)\n",
    "            img = img.to('cuda')\n",
    "            img = img.float()/255.0\n",
    "\n",
    "            f2 = open(opath + image + '_helper', 'r')\n",
    "            f2_line = f2.read()\n",
    "            f2.close()\n",
    "\n",
    "            image_max, image_min = f2_line.split(',')\n",
    "            image_max = float(image_max)\n",
    "            image_min = float(image_min)\n",
    "\n",
    "            img = img * (image_max - image_min) + image_min\n",
    "\n",
    "            middle = middles[int(math.log2(image_c))]\n",
    "            img = middle.out_layer(img)\n",
    "            pred = server(img)\n",
    "            pred = torch.argmax(pred, dim=1)    \n",
    "            preds.append(pred.item())\n",
    "            e_time = time.time()\n",
    "            server_time.append(e_time - s_time)\n",
    "\n",
    "    preds = torch.tensor(preds)\n",
    "    accuracy = [0] * 10 \n",
    "    server_time_box = [0] * 10\n",
    "    # calculate the accuracy every 60 frames\n",
    "    for i in range(0, 600, 60):\n",
    "        accuracy[i//60] = torch.sum(preds[i:i+60] == labels[i:i+60]).item() / 60\n",
    "        server_time_box[i//60] = sum(server_time[i:i+60]) / 60*1000\n",
    "\n",
    "    print(opath)\n",
    "    # change it to 4 float \n",
    "    for i in range(10):\n",
    "        accuracy[i] = float(str('%.4f'%accuracy[i]))\n",
    "        server_time_box[i] = float(str('%.4f'%server_time_box[i]))\n",
    "    print(accuracy)\n",
    "    print(server_time_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/imagenet-resnet-gate-emb/\n",
      "[0.7667, 0.7167, 0.8667, 0.7333, 0.7333, 0.75, 0.8667, 0.7833, 0.8, 0.85]\n",
      "[3.4139, 3.3888, 3.402, 3.477, 3.4073, 3.3982, 3.3837, 3.3911, 3.3917, 3.4164]\n"
     ]
    }
   ],
   "source": [
    "# load embbeded \n",
    "dataset = 'imagenet'\n",
    "model = 'reset'\n",
    "\n",
    "out_path = ['../data/imagenet-resnet-gate-emb/']\n",
    "\n",
    "import torch\n",
    "from Models import mobilenetv2, resnet\n",
    "from torchvision import transforms\n",
    "import time\n",
    "import base64\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from Utils import utils\n",
    "import sys\n",
    "\n",
    "for opath in out_path:\n",
    "\n",
    "    _, server = resnet.resnet_splitter(num_classes=1000, weight_root='./Weights/'+dataset+'/', layers=50)\n",
    "    server = server.to('cuda')\n",
    "    server.eval()\n",
    "\n",
    "    root_path = '../data/'+'imagenet-20'+'-client/'\n",
    "    labels = root_path+'labels.txt'\n",
    "    labels = open(labels, 'r')\n",
    "    labels = labels.readlines()\n",
    "    labels = [x[:-1] for x in labels]\n",
    "    labels = torch.tensor([int(x) for x in labels])\n",
    "\n",
    "    images = [str(x) for x in range(600)]\n",
    "    preds = []\n",
    "\n",
    "    middle_sizes = [1,2,4,8,16,32]\n",
    "    middles = []\n",
    "    for i in range(len(middle_sizes)):\n",
    "        middles.append(resnet.resnet_middle(middle=middle_sizes[i]))\n",
    "        middles[i].load_state_dict(torch.load('./Weights/'+dataset+'/middle/resnet_imagenet_middle_'+str(middle_sizes[i])+'.pth'))\n",
    "        middles[i] = middles[i].to('cuda')\n",
    "        middles[i].eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        server_time = []\n",
    "        for image in images:\n",
    "\n",
    "            f2 = open(opath + image + '_helper', 'r')\n",
    "            f2_line = f2.read()\n",
    "            f2.close()\n",
    "            image_max, image_min = f2_line.split(',')\n",
    "            image_min, image_max = float(image_min), float(image_max)\n",
    "\n",
    "            image_path = opath + image\n",
    "            # check is the path exist\n",
    "            i_read = open(image_path, 'rb')\n",
    "            img = i_read.read()\n",
    "            \n",
    "            # decode\n",
    "            s_time = time.time()\n",
    "            img = base64.b64decode(img)\n",
    "            img = np.frombuffer(img, dtype=np.uint8)\n",
    "            image_len = len(img)\n",
    "            image_c = int(image_len/56/56)\n",
    "            img = np.reshape(img, (image_c, 56, 56))\n",
    "            \n",
    "            img = torch.tensor(img)\n",
    "            img = img.unsqueeze(0)\n",
    "            img = utils.uint_to_float(img)\n",
    "            img = utils.renormalize(img, image_min, image_max)\n",
    "            img = img.to('cuda')\n",
    "\n",
    "            c_gate = int(math.log2(image_c))\n",
    "            if c_gate < len(middle_sizes):\n",
    "                img = middles[c_gate].out_layer(img)\n",
    "            pred = server(img)\n",
    "            pred = torch.argmax(pred, dim=1)    \n",
    "            preds.append(pred.item())\n",
    "            e_time = time.time()\n",
    "            server_time.append(e_time - s_time)\n",
    "\n",
    "    preds = torch.tensor(preds)\n",
    "    accuracy = [0] * 10 \n",
    "    server_time_box = [0] * 10\n",
    "    # calculate the accuracy every 60 frames\n",
    "    for i in range(0, 600, 60):\n",
    "        accuracy[i//60] = torch.sum(preds[i:i+60] == labels[i:i+60]).item() / 60\n",
    "        server_time_box[i//60] = sum(server_time[i:i+60]) / 60*1000\n",
    "\n",
    "    print(opath)\n",
    "    # change it to 4 float \n",
    "    for i in range(10):\n",
    "        accuracy[i] = float(str('%.4f'%accuracy[i]))\n",
    "        server_time_box[i] = float(str('%.4f'%server_time_box[i]))\n",
    "    print(accuracy)\n",
    "    print(server_time_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "tensor([1.2153, 0.4002, 0.6014, 1.0841, 1.0084, 0.6028, 0.4152, 0.3421, 0.4330,\n",
      "        0.7573, 0.9349, 0.8802, 0.7422, 0.3174, 0.4431, 0.7466, 0.9605, 1.0331,\n",
      "        0.8091, 1.0024, 0.9166, 0.9664, 0.9782, 1.0465, 1.0376, 0.6554, 0.4028,\n",
      "        0.5763, 0.7455, 0.6971, 0.6846, 0.8152, 0.7967, 0.9449, 0.8786, 0.6162,\n",
      "        0.5315, 0.6142, 0.7118, 0.6386, 0.6240, 0.6276, 0.6622, 0.6761, 0.6565,\n",
      "        0.5542, 0.6210, 0.7828, 0.7554, 0.7438, 0.8716, 0.7254, 0.5950, 0.3314,\n",
      "        0.3848, 0.8445], device='cuda:0')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m client_out \u001b[38;5;241m=\u001b[39m middle\u001b[38;5;241m.\u001b[39mout_layer(client_out)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(client_out[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 61\u001b[0m \u001b[43msys\u001b[49m\u001b[38;5;241m.\u001b[39mexit()\n\u001b[1;32m     62\u001b[0m server_out \u001b[38;5;241m=\u001b[39m server_r(client_out)\n\u001b[1;32m     63\u001b[0m pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(server_out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "# plot ground truth\n",
    "\n",
    "from Dataloaders import dataloader_cifar10, dataloader_image_20\n",
    "from Models import resnet, mobilenetv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# cifar-10\n",
    "_, test_c, _ = dataloader_cifar10.Dataloader_cifar10_val(test_batch=1)\n",
    "\n",
    "client_m, server_m = mobilenetv2.mobilenetv2_splitter(num_classes=10, weight_root='./Weights/cifar-10/')\n",
    "\n",
    "_, test_i, _, _ = dataloader_image_20.Dataloader_imagenet_20_integrated(test_batch=1)\n",
    "\n",
    "client_r, server_r = resnet.resnet_splitter(num_classes=1000, weight_root='./Weights/imagenet/', layers=50)\n",
    "\n",
    "client_m = client_m.to('cuda')\n",
    "client_m.eval()\n",
    "client_r = client_r.to('cuda')\n",
    "client_r.eval()\n",
    "server_m = server_m.to('cuda')\n",
    "server_m.eval()\n",
    "server_r = server_r.to('cuda')\n",
    "server_r.eval()\n",
    "\n",
    "accuracy_c = [0] * 600\n",
    "accuracy_i = [0] * 600\n",
    "\n",
    "acc_c_box = [0] * 10\n",
    "acc_i_box = [0] * 10\n",
    "\n",
    "middle = resnet.resnet_middle(middle=8)\n",
    "middle.load_state_dict(torch.load('./Weights/imagenet/middle/resnet_imagenet_middle_8.pth'))\n",
    "middle = middle.to('cuda')\n",
    "middle.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (data, target) in enumerate(test_c):\n",
    "        break\n",
    "        if i >= 600:\n",
    "            break\n",
    "        data = data.to('cuda')\n",
    "        target = target.to('cuda')\n",
    "        client_out = client_m(data)\n",
    "        server_out = server_m(client_out)\n",
    "        pred = torch.argmax(server_out, dim=1)\n",
    "        accuracy_c[i] = torch.sum(pred == target).item() / 1\n",
    "    for i, (data, target, _) in enumerate(test_i):\n",
    "        if i >= 600:\n",
    "            break\n",
    "        data = data.to('cuda')\n",
    "        target = target.to('cuda')\n",
    "        client_out = client_r(data)\n",
    "        middle_in = middle.in_layer(client_out)\n",
    "        client_out, mmin, mmax = utils.normalize_return(middle_in)\n",
    "        client_out = utils.float_to_uint(client_out)\n",
    "        client_out = utils.uint_to_float(client_out)\n",
    "        client_out = utils.renormalize(client_out, mmin, mmax)\n",
    "        client_out = middle.out_layer(client_out)\n",
    "        print(client_out[0,0,0])\n",
    "        sys.exit()\n",
    "        server_out = server_r(client_out)\n",
    "        pred = torch.argmax(server_out, dim=1)\n",
    "        accuracy_i[i] = torch.sum(pred == target).item() / 1\n",
    "    \n",
    "for i in range(0, 600, 60):\n",
    "    acc_c_box[i//60] = sum(accuracy_c[i:i+60]) / 60\n",
    "    acc_i_box[i//60] = sum(accuracy_i[i:i+60]) / 60\n",
    "\n",
    "print('acc_c_box ', acc_c_box)\n",
    "print('acc_i_box ', acc_i_box)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
