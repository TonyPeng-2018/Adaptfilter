{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:03,  6.68it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 59\u001b[0m\n\u001b[1;32m     55\u001b[0m     labels_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((labels_tensor, labels), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# store the embedding\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membeddings/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mind\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(labels_tensor, embeddings_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(ind) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/iot/lib/python3.12/site-packages/torch/serialization.py:628\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 628\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/iot/lib/python3.12/site-packages/torch/serialization.py:862\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[1;32m    861\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[0;32m--> 862\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use the model in Model, and dataloader in Dataloaders\n",
    "# to train the model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from Models import mobilenetv2\n",
    "from Dataloaders import dataloader_cifar10\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import Config.external_paths as external_paths\n",
    "# get the dataset\n",
    "train, test, labels = dataloader_cifar10.Dataloader_cifar10(train_batch=128, test_batch=100, seed=2024)\n",
    "\n",
    "# 2. transfer the dataset to fit the model, for the training, client and server model are all on the server\n",
    "client_model, server_model = mobilenetv2.stupid_model_splitter(weight_path='./Weights/cifar-10/MobileNetV2.pth')\n",
    "\n",
    "# gating = some_gating_function()\n",
    "\n",
    "# reducer = some_reducer_funtion()\n",
    "\n",
    "# generator = some_generator_funtion()\n",
    "\n",
    "client_model = client_model.cuda()\n",
    "\n",
    "# infer the model\n",
    "client_model.eval()\n",
    "\n",
    "# create a file path\n",
    "embeddings_path = external_paths.tintin_path + 'embeddings/cifar-10/MobileNetV2/'\n",
    "embedding_tensor = None\n",
    "labels_tensor = None\n",
    "# the embedding of the model and store\n",
    "if not os.path.exists(embeddings_path):\n",
    "    os.makedirs(embeddings_path)\n",
    "if not os.path.exists(embeddings_path+ 'embeddings/'):\n",
    "    os.makedirs(embeddings_path+ 'embeddings/')\n",
    "if not os.path.exists(embeddings_path+ 'labels/'):\n",
    "    os.makedirs(embeddings_path+ 'labels/')\n",
    "with torch.no_grad():\n",
    "    for ind, data in tqdm(enumerate(train)):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = client_model(inputs)\n",
    "\n",
    "        outputs_cpu = outputs.cpu()\n",
    "        # if embedding_tensor is None:\n",
    "        #     embedding_tensor = outputs_cpu\n",
    "        #     labels_tensor = labels\n",
    "        # else:\n",
    "        #     embedding_tensor = torch.cat((embedding_tensor, outputs_cpu), dim=0)\n",
    "        #     labels_tensor = torch.cat((labels_tensor, labels), dim=0)\n",
    "        embedding_tensor = outputs_cpu\n",
    "        labels_tensor = labels\n",
    "        \n",
    "        # store the embedding\n",
    "\n",
    "        torch.save(embedding_tensor, embeddings_path + 'embeddings/' + str(ind) + '.pth')\n",
    "        torch.save(labels_tensor, embeddings_path + 'labels/' + str(ind) + '.pth')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:02, 155.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# this part of code is for getting the embeddings of the server output \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from Models import mobilenetv2\n",
    "from Dataloaders import dataloader_cifar10\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "# get the dataset\n",
    "train, test, labels = dataloader_cifar10.Dataloader_cifar10(train_batch=128, test_batch=100, seed=2024)\n",
    "\n",
    "# 2. transfer the dataset to fit the model, for the training, client and server model are all on the server\n",
    "client_model, server_model = mobilenetv2.stupid_model_splitter(weight_path='./Weights/cifar-10/MobileNetV2.pth')\n",
    "\n",
    "# gating = some_gating_function()\n",
    "\n",
    "# reducer = some_reducer_funtion()\n",
    "\n",
    "# generator = some_generator_funtion()\n",
    "\n",
    "client_model = client_model.cuda()\n",
    "server_model = server_model.cuda()\n",
    "\n",
    "# infer the model\n",
    "client_model.eval()\n",
    "server_model.eval()\n",
    "\n",
    "# create a file path\n",
    "embeddings_path = '../data/cifar-10-embedding-out/'\n",
    "embedding_tensor = None\n",
    "labels_tensor = None\n",
    "# the embedding of the model and store\n",
    "if not os.path.exists(embeddings_path):\n",
    "    os.makedirs(embeddings_path)\n",
    "if not os.path.exists(embeddings_path+ 'embeddings/'):\n",
    "    os.makedirs(embeddings_path+ 'embeddings/')\n",
    "with torch.no_grad():\n",
    "    for ind, data in tqdm(enumerate(train)):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = client_model(inputs)\n",
    "\n",
    "        # outputs_cpu = outputs.cpu()\n",
    "        # # if embedding_tensor is None:\n",
    "        # #     embedding_tensor = outputs_cpu\n",
    "        # #     labels_tensor = labels\n",
    "        # # else:\n",
    "        # #     embedding_tensor = torch.cat((embedding_tensor, outputs_cpu), dim=0)\n",
    "        # #     labels_tensor = torch.cat((labels_tensor, labels), dim=0)\n",
    "        # embedding_tensor = outputs_cpu\n",
    "        # labels_tensor = labels\n",
    "        outputs = server_model(outputs)\n",
    "        \n",
    "        # store the embedding\n",
    "\n",
    "        torch.save(outputs, embeddings_path + 'embeddings/' + str(ind) + '.pth')\n",
    "        # torch.save(labels_tensor, embeddings_path + 'labels-out/' + str(ind) + '.pth')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 8, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# this part of code is for getting transferred embeddings of the client model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from Models import mobilenetv2\n",
    "from Dataloaders import dataloader_cifar10\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "# get the dataset\n",
    "\n",
    "def calculate_entropy(embs, percentage):\n",
    "    # embs are torch tensors\n",
    "    # percentage shows the number of embeddings to select\n",
    "    embs_entropy = []\n",
    "    for i in range(embs.size(len(embs.size())-3)):\n",
    "        embs_entropy.append(scipy.stats.entropy(embs[:, i].reshape(-1))) # b, c\n",
    "    # get the top percentage of the channels\n",
    "    embs_entropy = np.array(embs_entropy)\n",
    "    indices = np.argsort(embs_entropy)\n",
    "    num_selected = int(embs.size(1) * percentage)\n",
    "    selected_indices = indices[:num_selected]\n",
    "    return selected_indices\n",
    "    # out b, c*p, h, w or c*p, h, w\n",
    "\n",
    "def ranker_entropy(embs, percentage):\n",
    "    # calculate the entropy of the embeddings\n",
    "    selected_indices = calculate_entropy(embs, percentage)\n",
    "    # select indice from test embeddings\n",
    "    selected_embeddings = embs[:, selected_indices] # b, c*p, h, w\n",
    "    return selected_embeddings, selected_indices\n",
    "\n",
    "\n",
    "train, test, labels = dataloader_cifar10.Dataloader_cifar10(train_batch=128, test_batch=100, seed=2024)\n",
    "\n",
    "# 2. transfer the dataset to fit the model, for the training, client and server model are all on the server\n",
    "client_model, server_model = mobilenetv2.stupid_model_splitter(weight_path='./Weights/cifar-10/MobileNetV2.pth')\n",
    "\n",
    "rankers = []\n",
    "rank_rate = [0.25, 0.5, 0.75]\n",
    "for rate in rank_rate:\n",
    "    rankers.append(ranker_entropy)\n",
    "# gating = some_gating_function()\n",
    "\n",
    "# reducer = some_reducer_funtion()\n",
    "\n",
    "# generator = some_generator_funtion()\n",
    "\n",
    "client_model = client_model.cuda()\n",
    "server_model = server_model.cuda()\n",
    "\n",
    "# infer the model\n",
    "client_model.eval()\n",
    "server_model.eval()\n",
    "\n",
    "# create a file path\n",
    "embeddings_paths = ['../data/cifar-10-embedding-entropy/' + str(x) + '/' for x in range(3)]\n",
    "# create path\n",
    "for embeddings_path in embeddings_paths:\n",
    "    if not os.path.exists(embeddings_path):\n",
    "        os.makedirs(embeddings_path)\n",
    "    if not os.path.exists(embeddings_path+ 'embeddings/'):\n",
    "        os.makedirs(embeddings_path+ 'embeddings/')\n",
    "\n",
    "embedding_tensor = None\n",
    "labels_tensor = None\n",
    "# the embedding of the model and store\n",
    "for embeddings_path in embeddings_paths:\n",
    "    if not os.path.exists(embeddings_path):\n",
    "        os.makedirs(embeddings_path)\n",
    "    if not os.path.exists(embeddings_path+ 'embeddings/'):\n",
    "        os.makedirs(embeddings_path+ 'embeddings/')\n",
    "with torch.no_grad():\n",
    "    for ind, data in tqdm(enumerate(train)):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = client_model(inputs)\n",
    "\n",
    "        # outputs_cpu = outputs.cpu()\n",
    "        # # if embedding_tensor is None:\n",
    "        # #     embedding_tensor = outputs_cpu\n",
    "        # #     labels_tensor = labels\n",
    "        # # else:\n",
    "        # #     embedding_tensor = torch.cat((embedding_tensor, outputs_cpu), dim=0)\n",
    "        # #     labels_tensor = torch.cat((labels_tensor, labels), dim=0)\n",
    "        # embedding_tensor = outputs_cpu\n",
    "        # labels_tensor = labels\n",
    "\n",
    "        # add rankers here\n",
    "        outputs = outputs.cpu()\n",
    "        emb1 = rankers[0](outputs, 0.25)\n",
    "        emb2 = rankers[1](outputs, 0.5)\n",
    "        emb3 = rankers[2](outputs, 0.75)\n",
    "        \n",
    "        # store the embedding\n",
    "        torch.save(emb1, embeddings_paths[0] + 'embeddings/' + str(ind) + '.pth')\n",
    "        torch.save(emb2, embeddings_paths[1] + 'embeddings/' + str(ind) + '.pth')\n",
    "        torch.save(emb3, embeddings_paths[2] + 'embeddings/' + str(ind) + '.pth')\n",
    "\n",
    "        # torch.save(labels_tensor, embeddings_path + 'labels-out/' + str(ind) + '.pth')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24  9  7 27 31 28 13 14 25  4 23  5 26 18 17 10]\n"
     ]
    }
   ],
   "source": [
    "# test ranker embedding\n",
    "p = '/home/tonypeng/Workspace1/adaptfilter/data/cifar-10-embedding-entropy/1/embeddings/0.pth'\n",
    "embs = torch.load(p)\n",
    "print(embs[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
