{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models import mobilenetv2, resnet, gatedmodel\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# import torch and torch.nn\n",
    "# convert torch to tflite\n",
    "# get client\n",
    "m_i_client, _ = mobilenetv2.mobilenetv2_splitter(num_classes=1000, weight_root=\"./Weights/\" + \"imagenet\" + \"/\")\n",
    "r_i_client, _  = resnet.resnet_splitter(num_classes=1000, weight_root=\"./Weights/\" + \"imagenet\" + \"/\", layers=50)\n",
    "\n",
    "m_c_client, _  = mobilenetv2.mobilenetv2_splitter(num_classes=10, weight_root=\"./Weights/\" + \"cifar-10\" + \"/\")\n",
    "r_c_client, _  = resnet.resnet_splitter(num_classes=10, weight_root=\"./Weights/\" + \"cifar-10\" + \"/\", layers=50)\n",
    "\n",
    "m_ch = [2**x for x in range(0, 5)]\n",
    "m_i_encoders =[]\n",
    "for ch in m_ch:\n",
    "    m_i_encoders.append(mobilenetv2.MobileNetV2_middle(middle=ch))\n",
    "    m_i_encoders[-1].load_state_dict(torch.load(\"./Weights/\"+ \"imagenet\"+ \"/middle/\"+ \"mobile\"+ \"_\"+ \"imagenet\"+ \"_middle_\"+ str(ch)+ \".pth\"))\n",
    "    m_i_encoders[-1] = m_i_encoders[-1].in_layer\n",
    "\n",
    "r_ch = [2**x for x in range(0, 6)]\n",
    "r_i_encoders = []\n",
    "for ch in r_ch:\n",
    "    r_i_encoders.append(resnet.resnet_middle(middle=ch))\n",
    "    r_i_encoders[-1].load_state_dict(torch.load(\"./Weights/\"+ \"imagenet\"+ \"/middle/\"+ \"resnet\"+ \"_\"+ \"imagenet\"+ \"_middle_\"+ str(ch)+ \".pth\"))\n",
    "    r_i_encoders[-1] = r_i_encoders[-1].in_layer\n",
    "\n",
    "m_c_encoders = []\n",
    "for ch in m_ch:\n",
    "    m_c_encoders.append(mobilenetv2.MobileNetV2_middle(middle=ch))\n",
    "    m_c_encoders[-1].load_state_dict(torch.load(\"./Weights/\"+ \"cifar-10\"+ \"/middle/\"+ \"mobile\"+ \"_\"+ \"cifar-10\"+ \"_middle_\"+ str(ch)+ \".pth\"))\n",
    "    m_c_encoders[-1] = m_c_encoders[-1].in_layer\n",
    "\n",
    "r_c_encoders = []\n",
    "for ch in r_ch:\n",
    "    r_c_encoders.append(resnet.resnet_middle(middle=ch))\n",
    "    r_c_encoders[-1].load_state_dict(torch.load(\"./Weights/\"+ \"cifar-10\"+ \"/middle/\"+ \"resnet\"+ \"_\"+ \"cifar-10\"+ \"_middle_\"+ str(ch)+ \".pth\"))\n",
    "    r_c_encoders[-1] = r_c_encoders[-1].in_layer\n",
    "\n",
    "m_i_gates = []\n",
    "for ch in m_ch:\n",
    "    m_i_gates.append(gatedmodel.ExitGate(in_planes=ch, height=112, width=112))\n",
    "    m_i_gates[-1].load_state_dict(torch.load(\"./Weights/\"+ \"imagenet\"+ \"/gate/\"+ \"mobile\"+ \"_\"+ \"imagenet\"+ \"_gate_\"+ str(ch)+ \".pth\"))\n",
    "\n",
    "r_i_gates = []\n",
    "for ch in r_ch:\n",
    "    r_i_gates.append(gatedmodel.ExitGate(in_planes=ch, height=56, width=56))\n",
    "    r_i_gates[-1].load_state_dict(torch.load(\"./Weights/\"+ \"imagenet\"+ \"/gate/\"+ \"resnet\"+ \"_\"+ \"imagenet\"+ \"_gate_\"+ str(ch)+ \".pth\"))\n",
    "\n",
    "m_c_gates = []\n",
    "for ch in m_ch:\n",
    "    m_c_gates.append(gatedmodel.ExitGate(in_planes=ch, height=16, width=16))\n",
    "    m_c_gates[-1].load_state_dict(torch.load(\"./Weights/\"+ \"cifar-10\"+ \"/gate/\"+ \"mobile\"+ \"_\"+ \"cifar-10\"+ \"_gate_\"+ str(ch)+ \".pth\"))\n",
    "\n",
    "r_c_gates = []\n",
    "for ch in r_ch:\n",
    "    r_c_gates.append(gatedmodel.ExitGate(in_planes=ch, height=8, width=8))\n",
    "    r_c_gates[-1].load_state_dict(torch.load(\"./Weights/\"+ \"cifar-10\"+ \"/gate/\"+ \"resnet\"+ \"_\"+ \"cifar-10\"+ \"_gate_\"+ str(ch)+ \".pth\"))\n",
    "\n",
    "# eval\n",
    "m_i_client.eval()\n",
    "r_i_client.eval()\n",
    "m_c_client.eval()\n",
    "r_c_client.eval()\n",
    "for x in m_i_encoders:\n",
    "    x.eval()\n",
    "for x in r_i_encoders:\n",
    "    x.eval()\n",
    "for x in m_c_encoders:\n",
    "    x.eval()\n",
    "for x in r_c_encoders:\n",
    "    x.eval()\n",
    "for x in m_i_gates:\n",
    "    x.eval()\n",
    "for x in r_i_gates:\n",
    "    x.eval()\n",
    "for x in m_c_gates:\n",
    "    x.eval()\n",
    "\n",
    "# quant them\n",
    "m_i_client = torch.ao.quantization.quantize_dynamic(m_i_client, {torch.nn.Linear, torch.nn.Conv2d}, dtype=torch.qint8)\n",
    "r_i_client = torch.ao.quantization.quantize_dynamic(r_i_client, {torch.nn.Linear, torch.nn.Conv2d}, dtype=torch.qint8)\n",
    "m_c_client = torch.ao.quantization.quantize_dynamic(m_c_client, {torch.nn.Linear, torch.nn.Conv2d}, dtype=torch.qint8)\n",
    "r_c_client = torch.ao.quantization.quantize_dynamic(r_c_client, {torch.nn.Linear, torch.nn.Conv2d}, dtype=torch.qint8)\n",
    "r_i_encoders = [torch.ao.quantization.quantize_dynamic(x, {torch.nn.Conv2d}, dtype=torch.qint8) for x in r_i_encoders]\n",
    "m_i_encoders = [torch.ao.quantization.quantize_dynamic(x, {torch.nn.Conv2d}, dtype=torch.qint8) for x in m_i_encoders]\n",
    "r_c_encoders = [torch.ao.quantization.quantize_dynamic(x, {torch.nn.Conv2d}, dtype=torch.qint8) for x in r_c_encoders]\n",
    "m_c_encoders = [torch.ao.quantization.quantize_dynamic(x, {torch.nn.Conv2d}, dtype=torch.qint8) for x in m_c_encoders]\n",
    "r_i_gates = [torch.ao.quantization.quantize_dynamic(x, {torch.nn.Conv2d}, dtype=torch.qint8) for x in r_i_gates]\n",
    "m_i_gates = [torch.ao.quantization.quantize_dynamic(x, {torch.nn.Conv2d}, dtype=torch.qint8) for x in m_i_gates]\n",
    "r_c_gates = [torch.ao.quantization.quantize_dynamic(x, {torch.nn.Conv2d}, dtype=torch.qint8) for x in r_c_gates]\n",
    "m_c_gates = [torch.ao.quantization.quantize_dynamic(x, {torch.nn.Conv2d}, dtype=torch.qint8) for x in m_c_gates]\n",
    "\n",
    "c_input = (torch.randn(1, 3, 32, 32))\n",
    "i_input = (torch.randn(1, 3, 224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(m_i_client, i_input, \"./Onnxmodel/m_i_client.onnx\", opset_version=12, input_names=[\"input\"], output_names=[\"output\"])\n",
    "torch.onnx.export(r_i_client, i_input, \"./Onnxmodel/r_i_client.onnx\", opset_version=12, input_names=[\"input\"], output_names=[\"output\"])\n",
    "torch.onnx.export(m_c_client, c_input, \"./Onnxmodel/m_c_client.onnx\", opset_version=12, input_names=[\"input\"], output_names=[\"output\"])\n",
    "torch.onnx.export(r_c_client, c_input, \"./Onnxmodel/r_c_client.onnx\", opset_version=12, input_names=[\"input\"], output_names=[\"output\"])\n",
    "\n",
    "m_c_input = torch.randn(1, 32, 16, 16)\n",
    "m_i_input = torch.randn(1, 32, 112, 112)\n",
    "for i in range(len(m_ch)):\n",
    "    m_c_g_input = torch.randn(1, m_ch[i], 16, 16)\n",
    "    m_i_g_input = torch.randn(1, m_ch[i], 112, 112)\n",
    "    torch.onnx.export(m_i_encoders[i], m_i_input, \"./Onnxmodel/m_i_encoders_\"+str(m_ch[i])+\".onnx\", opset_version=12, input_names=[\"input\"], output_names=[\"output\"])\n",
    "    torch.onnx.export(m_i_gates[i], m_i_g_input, \"./Onnxmodel/m_i_gates_\"+str(m_ch[i])+\".onnx\", opset_version=12)\n",
    "    torch.onnx.export(m_c_encoders[i], m_c_input, \"./Onnxmodel/m_c_encoders_\"+str(m_ch[i])+\".onnx\", opset_version=12, input_names=[\"input\"], output_names=[\"output\"])\n",
    "    torch.onnx.export(m_c_gates[i], m_c_g_input, \"./Onnxmodel/m_c_gates_\"+str(m_ch[i])+\".onnx\", opset_version=12, input_names=[\"input\"], output_names=[\"output\"])\n",
    "\n",
    "r_c_input = torch.randn(1, 64, 8, 8)\n",
    "r_i_input = torch.randn(1, 64, 56, 56)\n",
    "for i in range(len(r_ch)):\n",
    "    r_c_g_input = torch.randn(1, r_ch[i], 8, 8)\n",
    "    r_i_g_input = torch.randn(1, r_ch[i], 56, 56)\n",
    "    torch.onnx.export(r_i_encoders[i], r_i_input, \"./Onnxmodel/r_i_encoders_\"+str(r_ch[i])+\".onnx\", opset_version=12, input_names=[\"input\"], output_names=[\"output\"])\n",
    "    torch.onnx.export(r_i_gates[i], r_i_g_input, \"./Onnxmodel/r_i_gates_\"+str(r_ch[i])+\".onnx\", opset_version=12, input_names=[\"input\"], output_names=[\"output\"])\n",
    "    torch.onnx.export(r_c_encoders[i], r_c_input, \"./Onnxmodel/r_c_encoders_\"+str(r_ch[i])+\".onnx\", opset_version=12, input_names=[\"input\"], output_names=[\"output\"])\n",
    "    torch.onnx.export(r_c_gates[i], r_c_g_input, \"./Onnxmodel/r_c_gates_\"+str(r_ch[i])+\".onnx\", opset_version=12, input_names=[\"input\"], output_names=[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 17:01:13.157130: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-09 17:01:13.167037: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-09 17:01:13.167057: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-09 17:01:13.175780: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-09 17:01:13.764284: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_addons'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m m_c_gates_onnx \u001b[38;5;241m=\u001b[39m [onnx\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Onnxmodel/m_c_gates_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(m_ch[i])\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(m_ch))]\n\u001b[1;32m     16\u001b[0m r_c_gates_onnx \u001b[38;5;241m=\u001b[39m [onnx\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Onnxmodel/r_c_gates_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(r_ch[i])\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(r_ch))]\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prepare\n\u001b[1;32m     19\u001b[0m m_i_client_onnx_tf_prep \u001b[38;5;241m=\u001b[39m prepare(m_i_client_onnx)\n\u001b[1;32m     20\u001b[0m r_i_client_onnx_tf_prep \u001b[38;5;241m=\u001b[39m prepare(r_i_client_onnx)\n",
      "File \u001b[0;32m~/anaconda3/envs/iot/lib/python3.12/site-packages/onnx_tf/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "File \u001b[0;32m~/anaconda3/envs/iot/lib/python3.12/site-packages/onnx_tf/backend.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_unique_suffix\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m supports_device \u001b[38;5;28;01mas\u001b[39;00m common_supports_device\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandler_helper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_all_backend_handlers\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpb_wrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OnnxNode\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcommon\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/iot/lib/python3.12/site-packages/onnx_tf/common/handler_helper.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defs\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_handler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackendHandler\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcommon\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/iot/lib/python3.12/site-packages/onnx_tf/handlers/backend/hardmax.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfa\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_handler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackendHandler\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m onnx_op\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_addons'"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "m_i_client_onnx = onnx.load(\"./Onnxmodel/m_i_client.onnx\")\n",
    "r_i_client_onnx = onnx.load(\"./Onnxmodel/r_i_client.onnx\")\n",
    "m_c_client_onnx = onnx.load(\"./Onnxmodel/m_c_client.onnx\")\n",
    "r_c_client_onnx = onnx.load(\"./Onnxmodel/r_c_client.onnx\")\n",
    "\n",
    "m_i_encoders_onnx = [onnx.load(\"./Onnxmodel/m_i_encoders_\"+str(m_ch[i])+\".onnx\") for i in range(len(m_ch))]\n",
    "r_i_encoders_onnx = [onnx.load(\"./Onnxmodel/r_i_encoders_\"+str(r_ch[i])+\".onnx\") for i in range(len(r_ch))]\n",
    "m_c_encoders_onnx = [onnx.load(\"./Onnxmodel/m_c_encoders_\"+str(m_ch[i])+\".onnx\") for i in range(len(m_ch))]\n",
    "r_c_encoders_onnx = [onnx.load(\"./Onnxmodel/r_c_encoders_\"+str(r_ch[i])+\".onnx\") for i in range(len(r_ch))]\n",
    "\n",
    "m_i_gates_onnx = [onnx.load(\"./Onnxmodel/m_i_gates_\"+str(m_ch[i])+\".onnx\") for i in range(len(m_ch))]\n",
    "r_i_gates_onnx = [onnx.load(\"./Onnxmodel/r_i_gates_\"+str(r_ch[i])+\".onnx\") for i in range(len(r_ch))]\n",
    "m_c_gates_onnx = [onnx.load(\"./Onnxmodel/m_c_gates_\"+str(m_ch[i])+\".onnx\") for i in range(len(m_ch))]\n",
    "r_c_gates_onnx = [onnx.load(\"./Onnxmodel/r_c_gates_\"+str(r_ch[i])+\".onnx\") for i in range(len(r_ch))]\n",
    "\n",
    "# from onnx_tf.backend import prepare\n",
    "# m_i_client_onnx_tf_prep = prepare(m_i_client_onnx)\n",
    "# r_i_client_onnx_tf_prep = prepare(r_i_client_onnx)\n",
    "# m_c_client_onnx_tf_prep = prepare(m_c_client_onnx)\n",
    "# r_c_client_onnx_tf_prep = prepare(r_c_client_onnx)\n",
    "\n",
    "# m_i_encoders_onnx_tf_prep = [prepare(x) for x in m_i_encoders_onnx]\n",
    "# r_i_encoders_onnx_tf_prep = [prepare(x) for x in r_i_encoders_onnx]\n",
    "# m_c_encoders_onnx_tf_prep = [prepare(x) for x in m_c_encoders_onnx]\n",
    "# r_c_encoders_onnx_tf_prep = [prepare(x) for x in r_c_encoders_onnx]\n",
    "\n",
    "# m_i_gates_onnx_tf_prep = [prepare(x) for x in m_i_gates_onnx]\n",
    "# r_i_gates_onnx_tf_prep = [prepare(x) for x in r_i_gates_onnx]\n",
    "# m_c_gates_onnx_tf_prep = [prepare(x) for x in m_c_gates_onnx]\n",
    "# r_c_gates_onnx_tf_prep = [prepare(x) for x in r_c_gates_onnx]\n",
    "\n",
    "# m_i_client_onnx_tf_prep.export_graph(\"./Tflitemodel/m_i_client.pb\")\n",
    "# r_i_client_onnx_tf_prep.export_graph(\"./Tflitemodel/r_i_client.pb\")\n",
    "# m_c_client_onnx_tf_prep.export_graph(\"./Tflitemodel/m_c_client.pb\")\n",
    "# r_c_client_onnx_tf_prep.export_graph(\"./Tflitemodel/r_c_client.pb\")\n",
    "\n",
    "# for i in range(len(m_ch)):\n",
    "#     m_i_encoders_onnx_tf_prep[i].export_graph(\"./Tflitemodel/m_i_encoders_\"+str(m_ch[i])+\".pb\")\n",
    "#     m_i_gates_onnx_tf_prep[i].export_graph(\"./Tflitemodel/m_i_gates_\"+str(m_ch[i])+\".pb\")\n",
    "#     m_c_encoders_onnx_tf_prep[i].export_graph(\"./Tflitemodel/m_c_encoders_\"+str(m_ch[i])+\".pb\")\n",
    "#     m_c_gates_onnx_tf_prep[i].export_graph(\"./Tflitemodel/m_c_gates_\"+str(m_ch[i])+\".pb\")\n",
    "\n",
    "# for i in range(len(r_ch)):\n",
    "#     r_i_encoders_onnx_tf_prep[i].export_graph(\"./Tflitemodel/r_i_encoders_\"+str(r_ch[i])+\".pb\")\n",
    "#     r_i_gates_onnx_tf_prep[i].export_graph(\"./Tflitemodel/r_i_gates_\"+str(r_ch[i])+\".pb\")\n",
    "#     r_c_encoders_onnx_tf_prep[i].export_graph(\"./Tflitemodel/r_c_encoders_\"+str(r_ch[i])+\".pb\")\n",
    "#     r_c_gates_onnx_tf_prep[i].export_graph(\"./Tflitemodel/r_c_gates_\"+str(r_ch[i])+\".pb\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
